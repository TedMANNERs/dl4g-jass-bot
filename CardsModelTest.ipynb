{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cards Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from pathlib import Path\n",
    "from jass.train.label_play import LabelPlay\n",
    "from jass.logs.game_log_entry import GameLogEntry\n",
    "from jass.game.game_state_util import state_from_complete_game, calculate_starting_hands_from_game\n",
    "from jass.game.rule_schieber import RuleSchieber\n",
    "from examples.io.convert_swisslos_log_to_games import LogParserSwisslos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DA</th>\n",
       "      <th>DK</th>\n",
       "      <th>DQ</th>\n",
       "      <th>DJ</th>\n",
       "      <th>D10</th>\n",
       "      <th>D9</th>\n",
       "      <th>D8</th>\n",
       "      <th>D7</th>\n",
       "      <th>D6</th>\n",
       "      <th>HA</th>\n",
       "      <th>HK</th>\n",
       "      <th>HQ</th>\n",
       "      <th>HJ</th>\n",
       "      <th>H10</th>\n",
       "      <th>H9</th>\n",
       "      <th>H8</th>\n",
       "      <th>H7</th>\n",
       "      <th>H6</th>\n",
       "      <th>SA</th>\n",
       "      <th>SK</th>\n",
       "      <th>SQ</th>\n",
       "      <th>SJ</th>\n",
       "      <th>S10</th>\n",
       "      <th>S9</th>\n",
       "      <th>S8</th>\n",
       "      <th>S7</th>\n",
       "      <th>S6</th>\n",
       "      <th>CA</th>\n",
       "      <th>CK</th>\n",
       "      <th>CQ</th>\n",
       "      <th>CJ</th>\n",
       "      <th>C10</th>\n",
       "      <th>C9</th>\n",
       "      <th>C8</th>\n",
       "      <th>C7</th>\n",
       "      <th>C6</th>\n",
       "      <th>trump</th>\n",
       "      <th>played_card</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DA  DK  DQ  DJ  D10  D9  D8  D7  D6  HA  HK  HQ  HJ  H10  H9  H8  H7  H6  \\\n",
       "0   0   0   0   0    0   1   1   0   0   1   0   1   0    0   0   0   0   1   \n",
       "1   0   0   0   0    0   0   0   0   0   0   0   0   0    0   1   0   0   0   \n",
       "2   0   0   0   0    0   0   0   0   0   0   1   0   1    1   0   1   1   0   \n",
       "3   0   0   1   1    1   0   0   0   0   0   0   0   0    0   0   0   0   0   \n",
       "4   1   1   0   0    0   0   0   0   1   0   0   0   0    0   0   0   0   0   \n",
       "\n",
       "   SA  SK  SQ  SJ  S10  S9  S8  S7  S6  CA  CK  CQ  CJ  C10  C9  C8  C7  C6  \\\n",
       "0   1   0   1   0    0   0   1   0   0   0   0   0   0    1   0   0   0   0   \n",
       "1   0   0   0   0    0   0   0   0   0   0   0   0   0    0   0   0   0   0   \n",
       "2   0   0   0   0    0   0   0   0   0   0   0   0   0    0   0   0   0   0   \n",
       "3   0   0   0   1    1   0   0   1   0   0   0   1   0    0   1   0   1   0   \n",
       "4   0   0   0   0    0   1   0   0   0   0   1   0   1    0   0   1   0   1   \n",
       "\n",
       "   trump  played_card  \n",
       "0      1            9  \n",
       "1      1           14  \n",
       "2      1           13  \n",
       "3      1            4  \n",
       "4      1           30  "
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cards = [\n",
    "# Diamonds\n",
    "'DA','DK','DQ','DJ','D10','D9','D8','D7','D6',\n",
    "# Hearts\n",
    "'HA','HK','HQ','HJ','H10','H9','H8','H7','H6',\n",
    "# Spades\n",
    "'SA','SK','SQ','SJ','S10','S9','S8','S7','S6',\n",
    "# Clubs\n",
    "'CA','CK','CQ','CJ','C10','C9','C8','C7','C6'\n",
    "]\n",
    "\n",
    "user  = ['user']\n",
    "trump = ['trump']\n",
    "played_card  = ['played_card']\n",
    "\n",
    "rule = RuleSchieber()\n",
    "\n",
    "entries = []\n",
    "path = Path(\"../jass-games\") / \"jass_game_0001.txt\"\n",
    "with open(path) as file:\n",
    "    line = file.readline()\n",
    "    #while line:\n",
    "    for x in range(50000):\n",
    "        content = json.loads(line)\n",
    "        entry = GameLogEntry.from_json(content)\n",
    "        entries.append(entry)\n",
    "        line = file.readline()\n",
    "\n",
    "#entries = LogParserSwisslos.parse_rounds(path)\n",
    "\n",
    "rows = []\n",
    "\n",
    "for entry in entries:\n",
    "    for nrCards in range(0,34):\n",
    "        round_state = state_from_complete_game(entry.game, nrCards)\n",
    "        valid_cards = rule.get_valid_cards_from_state(round_state)# valid cards for player\n",
    "        row = valid_cards\n",
    "        \n",
    "        row = np.append(row, round_state.trump)\n",
    "        \n",
    "        next_round_state = state_from_complete_game(entry.game, nrCards + 1)\n",
    "        #print(round_state.current_trick)\n",
    "        #print(next_round_state.tricks[round_state.nr_tricks])\n",
    "        card = np.setdiff1d(next_round_state.tricks[round_state.nr_tricks], round_state.current_trick)\n",
    "        #print(card)\n",
    "        row = np.append(row,card[0])\n",
    "        rows.append(row)\n",
    "\n",
    "data =pd.DataFrame(data=rows ,columns=cards + trump + played_card)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import player statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stats = pd.read_json(\"04 Data/stat/player_all_stat.json\")\n",
    "#stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#stats.sort_values(by=['mean'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop bad players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "#good_users = stats.loc[(stats['mean'] > 79) & (stats['nr'] > 5)]\n",
    "#good_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data = data[data['user'].isin(good_users['id'])]\n",
    "#data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "feature_columns = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_data = data[cards + trump + feature_columns]\n",
    "y_data = data.played_card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1427879    27\n",
      "570583      0\n",
      "1022463     5\n",
      "320809     10\n",
      "933715     13\n",
      "           ..\n",
      "1449789    25\n",
      "852204      6\n",
      "875922      9\n",
      "651560     19\n",
      "1277594    17\n",
      "Name: played_card, Length: 1360000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train_data, y_test_data = train_test_split(x_data, y_data, test_size=0.2, stratify=data.played_card, random_state=42)\n",
    "\n",
    "print(y_train_data)\n",
    "#y_train_label = np.argmax(x_train, axis=1)\n",
    "#y_categorical = tf.keras.utils.to_categorical(y_train_label, num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0   1   2   3   4   5   6   7   8   9   10  11  12  13  14  15  16  \\\n",
      "1427879   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "570583    1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "1022463   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   \n",
      "320809    0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   \n",
      "933715    0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   \n",
      "...      ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..   \n",
      "1449789   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "852204    0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   \n",
      "875922    0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   \n",
      "651560    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "1277594   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "\n",
      "         17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  \\\n",
      "1427879   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   \n",
      "570583    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "1022463   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "320809    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "933715    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "...      ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..   \n",
      "1449789   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   \n",
      "852204    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "875922    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "651560    0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "1277594   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "\n",
      "         34  35  \n",
      "1427879   0   0  \n",
      "570583    0   0  \n",
      "1022463   0   0  \n",
      "320809    0   0  \n",
      "933715    0   0  \n",
      "...      ..  ..  \n",
      "1449789   0   0  \n",
      "852204    0   0  \n",
      "875922    0   0  \n",
      "651560    0   0  \n",
      "1277594   0   0  \n",
      "\n",
      "[1360000 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "y_train = pd.get_dummies(y_train_data)\n",
    "y_test = pd.get_dummies(y_test_data)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "10187/10200 [============================>.] - ETA: 0s - loss: 2.9388 - accuracy: 0.1922WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 2.9379 - accuracy: 0.1924 - val_loss: 1.9171 - val_accuracy: 0.4315\n",
      "Epoch 2/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 2.0570 - accuracy: 0.3837 - val_loss: 1.7103 - val_accuracy: 0.4676\n",
      "Epoch 3/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.8901 - accuracy: 0.4102 - val_loss: 1.5790 - val_accuracy: 0.4751\n",
      "Epoch 4/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.8118 - accuracy: 0.4223 - val_loss: 1.5290 - val_accuracy: 0.4827\n",
      "Epoch 5/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.7646 - accuracy: 0.4296 - val_loss: 1.4768 - val_accuracy: 0.4908\n",
      "Epoch 6/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.7277 - accuracy: 0.4360 - val_loss: 1.4547 - val_accuracy: 0.4937\n",
      "Epoch 7/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.7027 - accuracy: 0.4389 - val_loss: 1.4300 - val_accuracy: 0.4985\n",
      "Epoch 8/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.6843 - accuracy: 0.4431 - val_loss: 1.4149 - val_accuracy: 0.5015\n",
      "Epoch 9/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.6711 - accuracy: 0.4450 - val_loss: 1.4147 - val_accuracy: 0.5031\n",
      "Epoch 10/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.6608 - accuracy: 0.4481 - val_loss: 1.4037 - val_accuracy: 0.5044\n",
      "Epoch 11/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.6508 - accuracy: 0.4503 - val_loss: 1.3924 - val_accuracy: 0.5085\n",
      "Epoch 12/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.6434 - accuracy: 0.4521 - val_loss: 1.3944 - val_accuracy: 0.5105\n",
      "Epoch 13/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.6353 - accuracy: 0.4546 - val_loss: 1.3861 - val_accuracy: 0.5118\n",
      "Epoch 14/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.6276 - accuracy: 0.4561 - val_loss: 1.3776 - val_accuracy: 0.5141\n",
      "Epoch 15/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.6215 - accuracy: 0.4580 - val_loss: 1.3807 - val_accuracy: 0.5144\n",
      "Epoch 16/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.6153 - accuracy: 0.4592 - val_loss: 1.3647 - val_accuracy: 0.5155\n",
      "Epoch 17/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.6088 - accuracy: 0.4607 - val_loss: 1.3562 - val_accuracy: 0.5196\n",
      "Epoch 18/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.6026 - accuracy: 0.4616 - val_loss: 1.3517 - val_accuracy: 0.5184\n",
      "Epoch 19/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.5977 - accuracy: 0.4630 - val_loss: 1.3499 - val_accuracy: 0.5186\n",
      "Epoch 20/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.5914 - accuracy: 0.4648 - val_loss: 1.3490 - val_accuracy: 0.5176\n",
      "Epoch 21/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.5871 - accuracy: 0.4655 - val_loss: 1.3410 - val_accuracy: 0.5191\n",
      "Epoch 22/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.5818 - accuracy: 0.4670 - val_loss: 1.3371 - val_accuracy: 0.5211\n",
      "Epoch 23/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.5776 - accuracy: 0.4678 - val_loss: 1.3277 - val_accuracy: 0.5218\n",
      "Epoch 24/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.5743 - accuracy: 0.4679 - val_loss: 1.3363 - val_accuracy: 0.5164\n",
      "Epoch 25/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.5707 - accuracy: 0.4679 - val_loss: 1.3282 - val_accuracy: 0.5235\n",
      "Epoch 26/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.5671 - accuracy: 0.4695 - val_loss: 1.3296 - val_accuracy: 0.5230\n",
      "Epoch 27/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.5628 - accuracy: 0.4702 - val_loss: 1.3208 - val_accuracy: 0.5255\n",
      "Epoch 28/300\n",
      "10200/10200 [==============================] - 21s 2ms/step - loss: 1.5602 - accuracy: 0.4701 - val_loss: 1.3115 - val_accuracy: 0.5256\n",
      "Epoch 29/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.5565 - accuracy: 0.4713 - val_loss: 1.3115 - val_accuracy: 0.5265\n",
      "Epoch 30/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.5528 - accuracy: 0.4716 - val_loss: 1.3049 - val_accuracy: 0.5264\n",
      "Epoch 31/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.5471 - accuracy: 0.4738 - val_loss: 1.3064 - val_accuracy: 0.5257\n",
      "Epoch 32/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.5420 - accuracy: 0.4743 - val_loss: 1.2953 - val_accuracy: 0.5250\n",
      "Epoch 33/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.5349 - accuracy: 0.4766 - val_loss: 1.2918 - val_accuracy: 0.5286\n",
      "Epoch 34/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.5293 - accuracy: 0.4768 - val_loss: 1.2904 - val_accuracy: 0.5287\n",
      "Epoch 35/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.5225 - accuracy: 0.4777 - val_loss: 1.2844 - val_accuracy: 0.5281\n",
      "Epoch 36/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.5167 - accuracy: 0.4777 - val_loss: 1.2839 - val_accuracy: 0.5263\n",
      "Epoch 37/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.5130 - accuracy: 0.4784 - val_loss: 1.2808 - val_accuracy: 0.5296\n",
      "Epoch 38/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.5096 - accuracy: 0.4791 - val_loss: 1.2718 - val_accuracy: 0.5303\n",
      "Epoch 39/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.5064 - accuracy: 0.4795 - val_loss: 1.2669 - val_accuracy: 0.5321\n",
      "Epoch 40/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.5024 - accuracy: 0.4805 - val_loss: 1.2605 - val_accuracy: 0.5341\n",
      "Epoch 41/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4993 - accuracy: 0.4804 - val_loss: 1.2619 - val_accuracy: 0.5327\n",
      "Epoch 42/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4958 - accuracy: 0.4815 - val_loss: 1.2618 - val_accuracy: 0.5318\n",
      "Epoch 43/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4932 - accuracy: 0.4819 - val_loss: 1.2583 - val_accuracy: 0.5319\n",
      "Epoch 44/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4902 - accuracy: 0.4825 - val_loss: 1.2499 - val_accuracy: 0.5353\n",
      "Epoch 45/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4875 - accuracy: 0.4827 - val_loss: 1.2501 - val_accuracy: 0.5352\n",
      "Epoch 46/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4862 - accuracy: 0.4834 - val_loss: 1.2402 - val_accuracy: 0.5385\n",
      "Epoch 47/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4837 - accuracy: 0.4837 - val_loss: 1.2403 - val_accuracy: 0.5348\n",
      "Epoch 48/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4804 - accuracy: 0.4842 - val_loss: 1.2391 - val_accuracy: 0.5356\n",
      "Epoch 49/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4775 - accuracy: 0.4855 - val_loss: 1.2385 - val_accuracy: 0.5353\n",
      "Epoch 50/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4753 - accuracy: 0.4858 - val_loss: 1.2377 - val_accuracy: 0.5375\n",
      "Epoch 51/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4739 - accuracy: 0.4859 - val_loss: 1.2287 - val_accuracy: 0.5406\n",
      "Epoch 52/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4720 - accuracy: 0.4865 - val_loss: 1.2336 - val_accuracy: 0.5364\n",
      "Epoch 53/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4691 - accuracy: 0.4870 - val_loss: 1.2330 - val_accuracy: 0.5384\n",
      "Epoch 54/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4669 - accuracy: 0.4874 - val_loss: 1.2231 - val_accuracy: 0.5414\n",
      "Epoch 55/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4660 - accuracy: 0.4875 - val_loss: 1.2236 - val_accuracy: 0.5401\n",
      "Epoch 56/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4630 - accuracy: 0.4884 - val_loss: 1.2188 - val_accuracy: 0.5379\n",
      "Epoch 57/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4609 - accuracy: 0.4887 - val_loss: 1.2241 - val_accuracy: 0.5381\n",
      "Epoch 58/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4596 - accuracy: 0.4890 - val_loss: 1.2255 - val_accuracy: 0.5407\n",
      "Epoch 59/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4585 - accuracy: 0.4889 - val_loss: 1.2212 - val_accuracy: 0.5387\n",
      "Epoch 60/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4553 - accuracy: 0.4894 - val_loss: 1.2068 - val_accuracy: 0.5448\n",
      "Epoch 61/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.4540 - accuracy: 0.4897 - val_loss: 1.2106 - val_accuracy: 0.5430\n",
      "Epoch 62/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.4522 - accuracy: 0.4907 - val_loss: 1.2103 - val_accuracy: 0.5415\n",
      "Epoch 63/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4509 - accuracy: 0.4903 - val_loss: 1.2089 - val_accuracy: 0.5425\n",
      "Epoch 64/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4486 - accuracy: 0.4912 - val_loss: 1.2049 - val_accuracy: 0.5431\n",
      "Epoch 65/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4478 - accuracy: 0.4910 - val_loss: 1.2087 - val_accuracy: 0.5422\n",
      "Epoch 66/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4461 - accuracy: 0.4912 - val_loss: 1.2040 - val_accuracy: 0.5448\n",
      "Epoch 67/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4444 - accuracy: 0.4918 - val_loss: 1.1978 - val_accuracy: 0.5429\n",
      "Epoch 68/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4430 - accuracy: 0.4923 - val_loss: 1.1969 - val_accuracy: 0.5476\n",
      "Epoch 69/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4417 - accuracy: 0.4923 - val_loss: 1.1979 - val_accuracy: 0.5451\n",
      "Epoch 70/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4401 - accuracy: 0.4927 - val_loss: 1.2013 - val_accuracy: 0.5449\n",
      "Epoch 71/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4385 - accuracy: 0.4934 - val_loss: 1.1946 - val_accuracy: 0.5488\n",
      "Epoch 72/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4377 - accuracy: 0.4931 - val_loss: 1.1946 - val_accuracy: 0.5463\n",
      "Epoch 73/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4365 - accuracy: 0.4933 - val_loss: 1.1984 - val_accuracy: 0.5480\n",
      "Epoch 74/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4353 - accuracy: 0.4943 - val_loss: 1.1867 - val_accuracy: 0.5468\n",
      "Epoch 75/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4340 - accuracy: 0.4944 - val_loss: 1.1879 - val_accuracy: 0.5475\n",
      "Epoch 76/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4322 - accuracy: 0.4942 - val_loss: 1.1957 - val_accuracy: 0.5469\n",
      "Epoch 77/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4303 - accuracy: 0.4949 - val_loss: 1.1953 - val_accuracy: 0.5458\n",
      "Epoch 78/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4291 - accuracy: 0.4948 - val_loss: 1.1831 - val_accuracy: 0.5477\n",
      "Epoch 79/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4290 - accuracy: 0.4948 - val_loss: 1.1899 - val_accuracy: 0.5461\n",
      "Epoch 80/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4280 - accuracy: 0.4957 - val_loss: 1.1843 - val_accuracy: 0.5464\n",
      "Epoch 81/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4267 - accuracy: 0.4953 - val_loss: 1.1888 - val_accuracy: 0.5464\n",
      "Epoch 82/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4247 - accuracy: 0.4962 - val_loss: 1.1797 - val_accuracy: 0.5504\n",
      "Epoch 83/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4243 - accuracy: 0.4959 - val_loss: 1.1864 - val_accuracy: 0.5518\n",
      "Epoch 84/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4234 - accuracy: 0.4963 - val_loss: 1.1859 - val_accuracy: 0.5493\n",
      "Epoch 85/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4224 - accuracy: 0.4960 - val_loss: 1.1778 - val_accuracy: 0.5511\n",
      "Epoch 86/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4206 - accuracy: 0.4968 - val_loss: 1.1761 - val_accuracy: 0.5498\n",
      "Epoch 87/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4195 - accuracy: 0.4970 - val_loss: 1.1768 - val_accuracy: 0.5507\n",
      "Epoch 88/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4186 - accuracy: 0.4971 - val_loss: 1.1727 - val_accuracy: 0.5519\n",
      "Epoch 89/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4177 - accuracy: 0.4970 - val_loss: 1.1871 - val_accuracy: 0.5485\n",
      "Epoch 90/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4170 - accuracy: 0.4973 - val_loss: 1.1706 - val_accuracy: 0.5503\n",
      "Epoch 91/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4161 - accuracy: 0.4981 - val_loss: 1.1780 - val_accuracy: 0.5508\n",
      "Epoch 92/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4152 - accuracy: 0.4977 - val_loss: 1.1799 - val_accuracy: 0.5488\n",
      "Epoch 93/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4145 - accuracy: 0.4976 - val_loss: 1.1682 - val_accuracy: 0.5533\n",
      "Epoch 94/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.4135 - accuracy: 0.4981 - val_loss: 1.1724 - val_accuracy: 0.5527\n",
      "Epoch 95/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.4121 - accuracy: 0.4987 - val_loss: 1.1755 - val_accuracy: 0.5493\n",
      "Epoch 96/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4120 - accuracy: 0.4979 - val_loss: 1.1692 - val_accuracy: 0.5549\n",
      "Epoch 97/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4104 - accuracy: 0.4991 - val_loss: 1.1648 - val_accuracy: 0.5543\n",
      "Epoch 98/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4095 - accuracy: 0.4989 - val_loss: 1.1581 - val_accuracy: 0.5551\n",
      "Epoch 99/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4085 - accuracy: 0.4995 - val_loss: 1.1602 - val_accuracy: 0.5558\n",
      "Epoch 100/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4074 - accuracy: 0.4998 - val_loss: 1.1624 - val_accuracy: 0.5539\n",
      "Epoch 101/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4070 - accuracy: 0.5005 - val_loss: 1.1615 - val_accuracy: 0.5537\n",
      "Epoch 102/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4055 - accuracy: 0.5004 - val_loss: 1.1675 - val_accuracy: 0.5529\n",
      "Epoch 103/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4052 - accuracy: 0.5005 - val_loss: 1.1607 - val_accuracy: 0.5590\n",
      "Epoch 104/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4051 - accuracy: 0.5005 - val_loss: 1.1576 - val_accuracy: 0.5548\n",
      "Epoch 105/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4033 - accuracy: 0.5004 - val_loss: 1.1589 - val_accuracy: 0.5564\n",
      "Epoch 106/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4024 - accuracy: 0.5015 - val_loss: 1.1586 - val_accuracy: 0.5571\n",
      "Epoch 107/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4015 - accuracy: 0.5005 - val_loss: 1.1629 - val_accuracy: 0.5530\n",
      "Epoch 108/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4006 - accuracy: 0.5009 - val_loss: 1.1574 - val_accuracy: 0.5547\n",
      "Epoch 109/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.4003 - accuracy: 0.5010 - val_loss: 1.1585 - val_accuracy: 0.5564\n",
      "Epoch 110/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3998 - accuracy: 0.5010 - val_loss: 1.1629 - val_accuracy: 0.5521\n",
      "Epoch 111/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3996 - accuracy: 0.5014 - val_loss: 1.1582 - val_accuracy: 0.5536\n",
      "Epoch 112/300\n",
      "10200/10200 [==============================] - 21s 2ms/step - loss: 1.3979 - accuracy: 0.5019 - val_loss: 1.1568 - val_accuracy: 0.5561\n",
      "Epoch 113/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3973 - accuracy: 0.5018 - val_loss: 1.1594 - val_accuracy: 0.5549\n",
      "Epoch 114/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3961 - accuracy: 0.5021 - val_loss: 1.1650 - val_accuracy: 0.5557\n",
      "Epoch 115/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3955 - accuracy: 0.5021 - val_loss: 1.1564 - val_accuracy: 0.5564\n",
      "Epoch 116/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3943 - accuracy: 0.5025 - val_loss: 1.1546 - val_accuracy: 0.5567\n",
      "Epoch 117/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3941 - accuracy: 0.5024 - val_loss: 1.1570 - val_accuracy: 0.5559\n",
      "Epoch 118/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3938 - accuracy: 0.5029 - val_loss: 1.1536 - val_accuracy: 0.5557\n",
      "Epoch 119/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3928 - accuracy: 0.5028 - val_loss: 1.1609 - val_accuracy: 0.5568\n",
      "Epoch 120/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3916 - accuracy: 0.5032 - val_loss: 1.1473 - val_accuracy: 0.5583\n",
      "Epoch 121/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3917 - accuracy: 0.5032 - val_loss: 1.1438 - val_accuracy: 0.5590\n",
      "Epoch 122/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3905 - accuracy: 0.5039 - val_loss: 1.1586 - val_accuracy: 0.5556\n",
      "Epoch 123/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3897 - accuracy: 0.5032 - val_loss: 1.1479 - val_accuracy: 0.5592\n",
      "Epoch 124/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3892 - accuracy: 0.5038 - val_loss: 1.1460 - val_accuracy: 0.5591\n",
      "Epoch 125/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3883 - accuracy: 0.5039 - val_loss: 1.1474 - val_accuracy: 0.5605\n",
      "Epoch 126/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3873 - accuracy: 0.5044 - val_loss: 1.1484 - val_accuracy: 0.5558\n",
      "Epoch 127/300\n",
      "10200/10200 [==============================] - 21s 2ms/step - loss: 1.3864 - accuracy: 0.5043 - val_loss: 1.1480 - val_accuracy: 0.5577\n",
      "Epoch 128/300\n",
      "10200/10200 [==============================] - 21s 2ms/step - loss: 1.3877 - accuracy: 0.5034 - val_loss: 1.1442 - val_accuracy: 0.5601\n",
      "Epoch 129/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3852 - accuracy: 0.5040 - val_loss: 1.1453 - val_accuracy: 0.5584\n",
      "Epoch 130/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3854 - accuracy: 0.5043 - val_loss: 1.1461 - val_accuracy: 0.5572\n",
      "Epoch 131/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3845 - accuracy: 0.5046 - val_loss: 1.1454 - val_accuracy: 0.5587\n",
      "Epoch 132/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3843 - accuracy: 0.5047 - val_loss: 1.1376 - val_accuracy: 0.5620\n",
      "Epoch 133/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3838 - accuracy: 0.5053 - val_loss: 1.1439 - val_accuracy: 0.5580\n",
      "Epoch 134/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3830 - accuracy: 0.5048 - val_loss: 1.1408 - val_accuracy: 0.5562\n",
      "Epoch 135/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3823 - accuracy: 0.5051 - val_loss: 1.1406 - val_accuracy: 0.5578\n",
      "Epoch 136/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3821 - accuracy: 0.5045 - val_loss: 1.1476 - val_accuracy: 0.5586\n",
      "Epoch 137/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3810 - accuracy: 0.5052 - val_loss: 1.1425 - val_accuracy: 0.5614\n",
      "Epoch 138/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3811 - accuracy: 0.5051 - val_loss: 1.1481 - val_accuracy: 0.5583\n",
      "Epoch 139/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3799 - accuracy: 0.5056 - val_loss: 1.1432 - val_accuracy: 0.5598\n",
      "Epoch 140/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3794 - accuracy: 0.5056 - val_loss: 1.1384 - val_accuracy: 0.5629\n",
      "Epoch 141/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3791 - accuracy: 0.5057 - val_loss: 1.1409 - val_accuracy: 0.5581\n",
      "Epoch 142/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3782 - accuracy: 0.5060 - val_loss: 1.1327 - val_accuracy: 0.5624\n",
      "Epoch 143/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3771 - accuracy: 0.5063 - val_loss: 1.1393 - val_accuracy: 0.5582\n",
      "Epoch 144/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3773 - accuracy: 0.5060 - val_loss: 1.1348 - val_accuracy: 0.5601\n",
      "Epoch 145/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3759 - accuracy: 0.5070 - val_loss: 1.1399 - val_accuracy: 0.5605\n",
      "Epoch 146/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3760 - accuracy: 0.5066 - val_loss: 1.1397 - val_accuracy: 0.5620\n",
      "Epoch 147/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3760 - accuracy: 0.5062 - val_loss: 1.1369 - val_accuracy: 0.5615\n",
      "Epoch 148/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3750 - accuracy: 0.5065 - val_loss: 1.1423 - val_accuracy: 0.5583\n",
      "Epoch 149/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3741 - accuracy: 0.5069 - val_loss: 1.1399 - val_accuracy: 0.5618\n",
      "Epoch 150/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3735 - accuracy: 0.5071 - val_loss: 1.1373 - val_accuracy: 0.5608\n",
      "Epoch 151/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3734 - accuracy: 0.5070 - val_loss: 1.1380 - val_accuracy: 0.5566\n",
      "Epoch 152/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3728 - accuracy: 0.5080 - val_loss: 1.1351 - val_accuracy: 0.5617\n",
      "Epoch 153/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3720 - accuracy: 0.5073 - val_loss: 1.1372 - val_accuracy: 0.5597\n",
      "Epoch 154/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3713 - accuracy: 0.5073 - val_loss: 1.1375 - val_accuracy: 0.5619\n",
      "Epoch 155/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3714 - accuracy: 0.5075 - val_loss: 1.1277 - val_accuracy: 0.5647\n",
      "Epoch 156/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3703 - accuracy: 0.5076 - val_loss: 1.1302 - val_accuracy: 0.5594\n",
      "Epoch 157/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3695 - accuracy: 0.5074 - val_loss: 1.1311 - val_accuracy: 0.5632\n",
      "Epoch 158/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3691 - accuracy: 0.5075 - val_loss: 1.1322 - val_accuracy: 0.5608\n",
      "Epoch 159/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3702 - accuracy: 0.5078 - val_loss: 1.1386 - val_accuracy: 0.5595\n",
      "Epoch 160/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3682 - accuracy: 0.5084 - val_loss: 1.1340 - val_accuracy: 0.5615\n",
      "Epoch 161/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3679 - accuracy: 0.5081 - val_loss: 1.1241 - val_accuracy: 0.5632\n",
      "Epoch 162/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3677 - accuracy: 0.5080 - val_loss: 1.1306 - val_accuracy: 0.5618\n",
      "Epoch 163/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3674 - accuracy: 0.5078 - val_loss: 1.1227 - val_accuracy: 0.5649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 164/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3666 - accuracy: 0.5085 - val_loss: 1.1251 - val_accuracy: 0.5669\n",
      "Epoch 165/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3661 - accuracy: 0.5087 - val_loss: 1.1286 - val_accuracy: 0.5646\n",
      "Epoch 166/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3657 - accuracy: 0.5087 - val_loss: 1.1296 - val_accuracy: 0.5610\n",
      "Epoch 167/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3650 - accuracy: 0.5085 - val_loss: 1.1267 - val_accuracy: 0.5632\n",
      "Epoch 168/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3643 - accuracy: 0.5085 - val_loss: 1.1302 - val_accuracy: 0.5630\n",
      "Epoch 169/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3641 - accuracy: 0.5093 - val_loss: 1.1222 - val_accuracy: 0.5644\n",
      "Epoch 170/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3635 - accuracy: 0.5095 - val_loss: 1.1252 - val_accuracy: 0.5629\n",
      "Epoch 171/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3633 - accuracy: 0.5086 - val_loss: 1.1257 - val_accuracy: 0.5610\n",
      "Epoch 172/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3626 - accuracy: 0.5092 - val_loss: 1.1237 - val_accuracy: 0.5626\n",
      "Epoch 173/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3620 - accuracy: 0.5093 - val_loss: 1.1268 - val_accuracy: 0.5653\n",
      "Epoch 174/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3616 - accuracy: 0.5090 - val_loss: 1.1241 - val_accuracy: 0.5638\n",
      "Epoch 175/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3615 - accuracy: 0.5090 - val_loss: 1.1261 - val_accuracy: 0.5632\n",
      "Epoch 176/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3607 - accuracy: 0.5095 - val_loss: 1.1258 - val_accuracy: 0.5606\n",
      "Epoch 177/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3605 - accuracy: 0.5098 - val_loss: 1.1246 - val_accuracy: 0.5623\n",
      "Epoch 178/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3594 - accuracy: 0.5098 - val_loss: 1.1205 - val_accuracy: 0.5632\n",
      "Epoch 179/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3593 - accuracy: 0.5099 - val_loss: 1.1173 - val_accuracy: 0.5678\n",
      "Epoch 180/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3590 - accuracy: 0.5104 - val_loss: 1.1238 - val_accuracy: 0.5613\n",
      "Epoch 181/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3585 - accuracy: 0.5098 - val_loss: 1.1223 - val_accuracy: 0.5646\n",
      "Epoch 182/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3575 - accuracy: 0.5101 - val_loss: 1.1208 - val_accuracy: 0.5656\n",
      "Epoch 183/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3575 - accuracy: 0.5101 - val_loss: 1.1225 - val_accuracy: 0.5646\n",
      "Epoch 184/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3575 - accuracy: 0.5104 - val_loss: 1.1208 - val_accuracy: 0.5660\n",
      "Epoch 185/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3569 - accuracy: 0.5100 - val_loss: 1.1251 - val_accuracy: 0.5634\n",
      "Epoch 186/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3564 - accuracy: 0.5105 - val_loss: 1.1164 - val_accuracy: 0.5637\n",
      "Epoch 187/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3564 - accuracy: 0.5100 - val_loss: 1.1194 - val_accuracy: 0.5671\n",
      "Epoch 188/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3555 - accuracy: 0.5107 - val_loss: 1.1206 - val_accuracy: 0.5637\n",
      "Epoch 189/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3552 - accuracy: 0.5105 - val_loss: 1.1175 - val_accuracy: 0.5648\n",
      "Epoch 190/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3554 - accuracy: 0.5107 - val_loss: 1.1186 - val_accuracy: 0.5665\n",
      "Epoch 191/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3546 - accuracy: 0.5110 - val_loss: 1.1155 - val_accuracy: 0.5666\n",
      "Epoch 192/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3540 - accuracy: 0.5106 - val_loss: 1.1128 - val_accuracy: 0.5653\n",
      "Epoch 193/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3540 - accuracy: 0.5110 - val_loss: 1.1179 - val_accuracy: 0.5674\n",
      "Epoch 194/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3536 - accuracy: 0.5103 - val_loss: 1.1155 - val_accuracy: 0.5645\n",
      "Epoch 195/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3533 - accuracy: 0.5103 - val_loss: 1.1143 - val_accuracy: 0.5671\n",
      "Epoch 196/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3526 - accuracy: 0.5108 - val_loss: 1.1193 - val_accuracy: 0.5636\n",
      "Epoch 197/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3519 - accuracy: 0.5113 - val_loss: 1.1170 - val_accuracy: 0.5671\n",
      "Epoch 198/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3520 - accuracy: 0.5114 - val_loss: 1.1162 - val_accuracy: 0.5643\n",
      "Epoch 199/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3508 - accuracy: 0.5109 - val_loss: 1.1138 - val_accuracy: 0.5664\n",
      "Epoch 200/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3506 - accuracy: 0.5117 - val_loss: 1.1090 - val_accuracy: 0.5682\n",
      "Epoch 201/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3503 - accuracy: 0.5116 - val_loss: 1.1134 - val_accuracy: 0.5639\n",
      "Epoch 202/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3500 - accuracy: 0.5119 - val_loss: 1.1197 - val_accuracy: 0.5655\n",
      "Epoch 203/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3494 - accuracy: 0.5114 - val_loss: 1.1180 - val_accuracy: 0.5638\n",
      "Epoch 204/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3491 - accuracy: 0.5118 - val_loss: 1.1102 - val_accuracy: 0.5666\n",
      "Epoch 205/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3486 - accuracy: 0.5120 - val_loss: 1.1114 - val_accuracy: 0.5678\n",
      "Epoch 206/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3489 - accuracy: 0.5117 - val_loss: 1.1128 - val_accuracy: 0.5663\n",
      "Epoch 207/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3484 - accuracy: 0.5118 - val_loss: 1.1110 - val_accuracy: 0.5687\n",
      "Epoch 208/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3480 - accuracy: 0.5123 - val_loss: 1.1134 - val_accuracy: 0.5670\n",
      "Epoch 209/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3467 - accuracy: 0.5124 - val_loss: 1.1116 - val_accuracy: 0.5688\n",
      "Epoch 210/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3465 - accuracy: 0.5128 - val_loss: 1.1094 - val_accuracy: 0.5693\n",
      "Epoch 211/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3461 - accuracy: 0.5128 - val_loss: 1.1098 - val_accuracy: 0.5678\n",
      "Epoch 212/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3473 - accuracy: 0.5116 - val_loss: 1.1105 - val_accuracy: 0.5695\n",
      "Epoch 213/300\n",
      "10200/10200 [==============================] - 21s 2ms/step - loss: 1.3458 - accuracy: 0.5125 - val_loss: 1.1164 - val_accuracy: 0.5659\n",
      "Epoch 214/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3453 - accuracy: 0.5132 - val_loss: 1.1054 - val_accuracy: 0.5686\n",
      "Epoch 215/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3444 - accuracy: 0.5128 - val_loss: 1.1073 - val_accuracy: 0.5699\n",
      "Epoch 216/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3434 - accuracy: 0.5135 - val_loss: 1.1074 - val_accuracy: 0.5677\n",
      "Epoch 217/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3422 - accuracy: 0.5140 - val_loss: 1.1085 - val_accuracy: 0.5671\n",
      "Epoch 218/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3402 - accuracy: 0.5145 - val_loss: 1.1054 - val_accuracy: 0.5651\n",
      "Epoch 219/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3371 - accuracy: 0.5153 - val_loss: 1.1045 - val_accuracy: 0.5669\n",
      "Epoch 220/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3360 - accuracy: 0.5155 - val_loss: 1.1062 - val_accuracy: 0.5673\n",
      "Epoch 221/300\n",
      "10200/10200 [==============================] - 21s 2ms/step - loss: 1.3341 - accuracy: 0.5160 - val_loss: 1.1028 - val_accuracy: 0.5666\n",
      "Epoch 222/300\n",
      "10200/10200 [==============================] - 21s 2ms/step - loss: 1.3344 - accuracy: 0.5152 - val_loss: 1.1089 - val_accuracy: 0.5662\n",
      "Epoch 223/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3323 - accuracy: 0.5151 - val_loss: 1.1026 - val_accuracy: 0.5702\n",
      "Epoch 224/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3329 - accuracy: 0.5144 - val_loss: 1.1090 - val_accuracy: 0.5674\n",
      "Epoch 225/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3318 - accuracy: 0.5158 - val_loss: 1.1043 - val_accuracy: 0.5703\n",
      "Epoch 226/300\n",
      "10200/10200 [==============================] - 22s 2ms/step - loss: 1.3304 - accuracy: 0.5156 - val_loss: 1.0977 - val_accuracy: 0.5691\n",
      "Epoch 227/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3316 - accuracy: 0.5149 - val_loss: 1.0970 - val_accuracy: 0.5682\n",
      "Epoch 228/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3301 - accuracy: 0.5154 - val_loss: 1.0996 - val_accuracy: 0.5678\n",
      "Epoch 229/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3298 - accuracy: 0.5153 - val_loss: 1.1009 - val_accuracy: 0.5688\n",
      "Epoch 230/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3292 - accuracy: 0.5154 - val_loss: 1.1017 - val_accuracy: 0.5695\n",
      "Epoch 231/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3293 - accuracy: 0.5159 - val_loss: 1.0937 - val_accuracy: 0.5706\n",
      "Epoch 232/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3287 - accuracy: 0.5157 - val_loss: 1.1009 - val_accuracy: 0.5681\n",
      "Epoch 233/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3290 - accuracy: 0.5154 - val_loss: 1.1006 - val_accuracy: 0.5679\n",
      "Epoch 234/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3284 - accuracy: 0.5151 - val_loss: 1.0992 - val_accuracy: 0.5688\n",
      "Epoch 235/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3275 - accuracy: 0.5157 - val_loss: 1.0940 - val_accuracy: 0.5686\n",
      "Epoch 236/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3264 - accuracy: 0.5162 - val_loss: 1.0966 - val_accuracy: 0.5690\n",
      "Epoch 237/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3267 - accuracy: 0.5154 - val_loss: 1.0974 - val_accuracy: 0.5695\n",
      "Epoch 238/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3255 - accuracy: 0.5166 - val_loss: 1.1005 - val_accuracy: 0.5682\n",
      "Epoch 239/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3257 - accuracy: 0.5160 - val_loss: 1.0953 - val_accuracy: 0.5702\n",
      "Epoch 240/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3256 - accuracy: 0.5160 - val_loss: 1.0947 - val_accuracy: 0.5685\n",
      "Epoch 241/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3252 - accuracy: 0.5157 - val_loss: 1.1020 - val_accuracy: 0.5660\n",
      "Epoch 242/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3249 - accuracy: 0.5161 - val_loss: 1.0928 - val_accuracy: 0.5703\n",
      "Epoch 243/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3249 - accuracy: 0.5161 - val_loss: 1.0960 - val_accuracy: 0.5665\n",
      "Epoch 244/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3233 - accuracy: 0.5165 - val_loss: 1.0948 - val_accuracy: 0.5672\n",
      "Epoch 245/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3239 - accuracy: 0.5161 - val_loss: 1.0955 - val_accuracy: 0.5710\n",
      "Epoch 246/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3229 - accuracy: 0.5159 - val_loss: 1.0943 - val_accuracy: 0.5688\n",
      "Epoch 247/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3231 - accuracy: 0.5167 - val_loss: 1.0950 - val_accuracy: 0.5709\n",
      "Epoch 248/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3226 - accuracy: 0.5157 - val_loss: 1.0920 - val_accuracy: 0.5716\n",
      "Epoch 249/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3217 - accuracy: 0.5160 - val_loss: 1.0938 - val_accuracy: 0.5689\n",
      "Epoch 250/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3209 - accuracy: 0.5166 - val_loss: 1.0948 - val_accuracy: 0.5689\n",
      "Epoch 251/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3215 - accuracy: 0.5168 - val_loss: 1.0878 - val_accuracy: 0.5728\n",
      "Epoch 252/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3201 - accuracy: 0.5167 - val_loss: 1.0902 - val_accuracy: 0.5706\n",
      "Epoch 253/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3208 - accuracy: 0.5164 - val_loss: 1.0969 - val_accuracy: 0.5715\n",
      "Epoch 254/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3195 - accuracy: 0.5166 - val_loss: 1.0973 - val_accuracy: 0.5665\n",
      "Epoch 255/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3197 - accuracy: 0.5167 - val_loss: 1.0923 - val_accuracy: 0.5674\n",
      "Epoch 256/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3201 - accuracy: 0.5170 - val_loss: 1.0915 - val_accuracy: 0.5738\n",
      "Epoch 257/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3190 - accuracy: 0.5165 - val_loss: 1.0873 - val_accuracy: 0.5733\n",
      "Epoch 258/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3178 - accuracy: 0.5172 - val_loss: 1.0911 - val_accuracy: 0.5700\n",
      "Epoch 259/300\n",
      "10200/10200 [==============================] - 21s 2ms/step - loss: 1.3179 - accuracy: 0.5172 - val_loss: 1.0874 - val_accuracy: 0.5718\n",
      "Epoch 260/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3186 - accuracy: 0.5166 - val_loss: 1.0960 - val_accuracy: 0.5699\n",
      "Epoch 261/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3181 - accuracy: 0.5169 - val_loss: 1.0921 - val_accuracy: 0.5680\n",
      "Epoch 262/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3173 - accuracy: 0.5175 - val_loss: 1.0907 - val_accuracy: 0.5690\n",
      "Epoch 263/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3169 - accuracy: 0.5172 - val_loss: 1.0874 - val_accuracy: 0.5687\n",
      "Epoch 264/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3171 - accuracy: 0.5172 - val_loss: 1.0857 - val_accuracy: 0.5696\n",
      "Epoch 265/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3162 - accuracy: 0.5173 - val_loss: 1.0895 - val_accuracy: 0.5683\n",
      "Epoch 266/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3164 - accuracy: 0.5167 - val_loss: 1.0931 - val_accuracy: 0.5672\n",
      "Epoch 267/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3157 - accuracy: 0.5172 - val_loss: 1.0832 - val_accuracy: 0.5741\n",
      "Epoch 268/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3158 - accuracy: 0.5173 - val_loss: 1.0838 - val_accuracy: 0.5714\n",
      "Epoch 269/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3160 - accuracy: 0.5171 - val_loss: 1.0857 - val_accuracy: 0.5738\n",
      "Epoch 270/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3156 - accuracy: 0.5175 - val_loss: 1.0866 - val_accuracy: 0.5751\n",
      "Epoch 271/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3152 - accuracy: 0.5177 - val_loss: 1.0870 - val_accuracy: 0.5703\n",
      "Epoch 272/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3145 - accuracy: 0.5178 - val_loss: 1.0875 - val_accuracy: 0.5687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 273/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3149 - accuracy: 0.5182 - val_loss: 1.0843 - val_accuracy: 0.5727\n",
      "Epoch 274/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3138 - accuracy: 0.5179 - val_loss: 1.0847 - val_accuracy: 0.5716\n",
      "Epoch 275/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3145 - accuracy: 0.5184 - val_loss: 1.0885 - val_accuracy: 0.5713\n",
      "Epoch 276/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3135 - accuracy: 0.5190 - val_loss: 1.0871 - val_accuracy: 0.5689\n",
      "Epoch 277/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3129 - accuracy: 0.5185 - val_loss: 1.0832 - val_accuracy: 0.5729\n",
      "Epoch 278/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3124 - accuracy: 0.5183 - val_loss: 1.0843 - val_accuracy: 0.5689\n",
      "Epoch 279/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3129 - accuracy: 0.5182 - val_loss: 1.0895 - val_accuracy: 0.5676\n",
      "Epoch 280/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3125 - accuracy: 0.5182 - val_loss: 1.0853 - val_accuracy: 0.5722\n",
      "Epoch 281/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3121 - accuracy: 0.5181 - val_loss: 1.0848 - val_accuracy: 0.5716\n",
      "Epoch 282/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3114 - accuracy: 0.5188 - val_loss: 1.0862 - val_accuracy: 0.5729\n",
      "Epoch 283/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3120 - accuracy: 0.5185 - val_loss: 1.0821 - val_accuracy: 0.5709\n",
      "Epoch 284/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3107 - accuracy: 0.5189 - val_loss: 1.0790 - val_accuracy: 0.5735\n",
      "Epoch 285/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3109 - accuracy: 0.5189 - val_loss: 1.0859 - val_accuracy: 0.5666\n",
      "Epoch 286/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3106 - accuracy: 0.5193 - val_loss: 1.0819 - val_accuracy: 0.5714\n",
      "Epoch 287/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3113 - accuracy: 0.5188 - val_loss: 1.0830 - val_accuracy: 0.5714\n",
      "Epoch 288/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3100 - accuracy: 0.5195 - val_loss: 1.0831 - val_accuracy: 0.5716\n",
      "Epoch 289/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3107 - accuracy: 0.5184 - val_loss: 1.0811 - val_accuracy: 0.5731\n",
      "Epoch 290/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3100 - accuracy: 0.5191 - val_loss: 1.0846 - val_accuracy: 0.5728\n",
      "Epoch 291/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3094 - accuracy: 0.5196 - val_loss: 1.0838 - val_accuracy: 0.5702\n",
      "Epoch 292/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3099 - accuracy: 0.5190 - val_loss: 1.0831 - val_accuracy: 0.5709\n",
      "Epoch 293/300\n",
      "10200/10200 [==============================] - 20s 2ms/step - loss: 1.3093 - accuracy: 0.5187 - val_loss: 1.0825 - val_accuracy: 0.5721\n",
      "Epoch 294/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3085 - accuracy: 0.5189 - val_loss: 1.0895 - val_accuracy: 0.5681\n",
      "Epoch 295/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3090 - accuracy: 0.5192 - val_loss: 1.0835 - val_accuracy: 0.5712\n",
      "Epoch 296/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3090 - accuracy: 0.5195 - val_loss: 1.0819 - val_accuracy: 0.5695\n",
      "Epoch 297/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3084 - accuracy: 0.5193 - val_loss: 1.0796 - val_accuracy: 0.5734\n",
      "Epoch 298/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3080 - accuracy: 0.5197 - val_loss: 1.0768 - val_accuracy: 0.5729\n",
      "Epoch 299/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3067 - accuracy: 0.5196 - val_loss: 1.0799 - val_accuracy: 0.5739\n",
      "Epoch 300/300\n",
      "10200/10200 [==============================] - 19s 2ms/step - loss: 1.3078 - accuracy: 0.5195 - val_loss: 1.0834 - val_accuracy: 0.5706\n"
     ]
    }
   ],
   "source": [
    "input_length = len(cards + trump + feature_columns)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(input_length, activation='relu', input_shape=[input_length]))\n",
    "model.add(keras.layers.Dense(120, activation='relu'))\n",
    "model.add(keras.layers.Dense(120, activation='relu'))\n",
    "model.add(keras.layers.Dense(54, activation='relu'))\n",
    "model.add(keras.layers.Dense(54, activation='relu'))\n",
    "model.add(keras.layers.Dense(40, activation='relu'))\n",
    "model.add(keras.layers.Dense(40, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Dense(36, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, validation_split=0.25, epochs=300, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10625/10625 [==============================] - 15s 1ms/step - loss: 1.0889 - accuracy: 0.5696\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.088873028755188, 0.5695676207542419]"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss')"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1e4044b8550>"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deal_random_hand() -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Deal random hand.\n",
    "\n",
    "    Returns:\n",
    "        one hot encoded 1x36 array\n",
    "    \"\"\"\n",
    "    # shuffle card ids\n",
    "    cards = np.arange(0, 36, dtype=np.int32)\n",
    "    np.random.shuffle(cards)\n",
    "    hands = np.zeros(shape=[4, 36], dtype=np.int32)\n",
    "\n",
    "    # convert to one hot encoded\n",
    "    hands[0, cards[0:9]] = 1\n",
    "    hands[1, cards[9:18]] = 1\n",
    "    hands[2, cards[18:27]] = 1\n",
    "    hands[3, cards[27:39]] = 1\n",
    "    \n",
    "    hand = np.append(hands[0], np.random.randint(0,5))\n",
    "\n",
    "    return hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'deal_random_hand' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-101756038c84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhand\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeal_random_hand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#hand = np.array([[0,1,1,1,0,1,0,0,0, 0,0,0,0,1,0,0,1,0, 1,0,0,0,0,0,0,0,0, 0,0,0,0,0,1,0,0,1, 4]])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mhand_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhand\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcards\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mtrump\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhand_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'deal_random_hand' is not defined"
     ]
    }
   ],
   "source": [
    "hand = deal_random_hand()\n",
    "#hand = np.array([[0,1,1,1,0,1,0,0,0, 0,0,0,0,1,0,0,1,0, 1,0,0,0,0,0,0,0,0, 0,0,0,0,0,1,0,0,1, 4]])\n",
    "hand_df = pd.DataFrame(data=[hand], columns=cards+trump)\n",
    "\n",
    "print(hand_df)\n",
    "print(\"\\n\")\n",
    "input_hand = np.array([hand_df.iloc[0].values])\n",
    "prediction = model.predict(input_hand)\n",
    "prediction = prediction * hand[:-1]\n",
    "result = pd.DataFrame(data=prediction, columns=cards)\n",
    "print(result)\n",
    "result.idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: E:/Work/cards_model50000_0569\\assets\n"
     ]
    }
   ],
   "source": [
    "#model.save(\"E:/Work/cards_model50000_0569\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
