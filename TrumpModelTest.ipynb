{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trump Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DA</th>\n",
       "      <th>DK</th>\n",
       "      <th>DQ</th>\n",
       "      <th>DJ</th>\n",
       "      <th>D10</th>\n",
       "      <th>D9</th>\n",
       "      <th>D8</th>\n",
       "      <th>D7</th>\n",
       "      <th>D6</th>\n",
       "      <th>HA</th>\n",
       "      <th>HK</th>\n",
       "      <th>HQ</th>\n",
       "      <th>HJ</th>\n",
       "      <th>H10</th>\n",
       "      <th>H9</th>\n",
       "      <th>H8</th>\n",
       "      <th>H7</th>\n",
       "      <th>H6</th>\n",
       "      <th>SA</th>\n",
       "      <th>SK</th>\n",
       "      <th>SQ</th>\n",
       "      <th>SJ</th>\n",
       "      <th>S10</th>\n",
       "      <th>S9</th>\n",
       "      <th>S8</th>\n",
       "      <th>S7</th>\n",
       "      <th>S6</th>\n",
       "      <th>CA</th>\n",
       "      <th>CK</th>\n",
       "      <th>CQ</th>\n",
       "      <th>CJ</th>\n",
       "      <th>C10</th>\n",
       "      <th>C9</th>\n",
       "      <th>C8</th>\n",
       "      <th>C7</th>\n",
       "      <th>C6</th>\n",
       "      <th>FH</th>\n",
       "      <th>user</th>\n",
       "      <th>trump</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53248</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4613</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>68780</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24555</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8392</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DA  DK  DQ  DJ  D10  D9  D8  D7  D6  HA  HK  HQ  HJ  H10  H9  H8  H7  H6  \\\n",
       "0   0   0   0   1    1   0   1   1   0   0   0   0   0    0   0   0   0   0   \n",
       "1   0   0   0   0    0   0   0   0   1   1   0   0   0    0   1   1   0   1   \n",
       "2   1   0   0   1    0   0   0   0   0   0   0   0   1    1   0   0   0   0   \n",
       "3   0   0   0   0    0   0   0   0   0   1   0   0   0    0   0   0   1   1   \n",
       "4   0   1   0   0    0   0   0   0   1   1   1   1   0    0   0   1   0   1   \n",
       "\n",
       "   SA  SK  SQ  SJ  S10  S9  S8  S7  S6  CA  CK  CQ  CJ  C10  C9  C8  C7  C6  \\\n",
       "0   1   0   1   1    0   0   0   0   0   0   0   1   0    0   0   1   0   0   \n",
       "1   0   0   0   0    1   0   0   1   0   0   0   0   1    0   0   0   1   0   \n",
       "2   1   1   0   0    0   0   0   0   0   0   0   1   0    0   0   0   1   1   \n",
       "3   0   0   1   0    0   0   1   0   1   1   0   0   0    1   1   0   0   0   \n",
       "4   0   0   0   0    0   0   0   1   0   0   0   0   1    0   0   0   0   0   \n",
       "\n",
       "   FH   user  trump  \n",
       "0   0  53248      6  \n",
       "1   0   4613      5  \n",
       "2   0  68780      6  \n",
       "3   0  24555      5  \n",
       "4   1   8392      4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_data = Path('SW 06')\n",
    "# Import only a fraction of data for efficient testing\n",
    "data = pd.read_csv(path_to_data / '2018_10_18_trump.csv', header=None)\n",
    "cards = [\n",
    "# Diamonds\n",
    "'DA','DK','DQ','DJ','D10','D9','D8','D7','D6',\n",
    "# Hearts\n",
    "'HA','HK','HQ','HJ','H10','H9','H8','H7','H6',\n",
    "# Spades\n",
    "'SA','SK','SQ','SJ','S10','S9','S8','S7','S6',\n",
    "# Clubs\n",
    "'CA','CK','CQ','CJ','C10','C9','C8','C7','C6'\n",
    "]\n",
    "\n",
    "# Forehand (yes = 1, no = 0)\n",
    "forehand = ['FH']\n",
    "\n",
    "user  = ['user']\n",
    "trump = ['trump']\n",
    "\n",
    "data.columns = cards + forehand + user + trump\n",
    "pd.set_option('display.max_columns', None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import player statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>nr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>78.433100</td>\n",
       "      <td>42.186764</td>\n",
       "      <td>1978858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6955</td>\n",
       "      <td>76.191936</td>\n",
       "      <td>41.780344</td>\n",
       "      <td>4241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54404</td>\n",
       "      <td>78.010880</td>\n",
       "      <td>41.985297</td>\n",
       "      <td>7445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74994</td>\n",
       "      <td>76.775460</td>\n",
       "      <td>41.428476</td>\n",
       "      <td>7669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56143</td>\n",
       "      <td>76.774029</td>\n",
       "      <td>41.546253</td>\n",
       "      <td>978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id       mean        std       nr\n",
       "0      0  78.433100  42.186764  1978858\n",
       "1   6955  76.191936  41.780344     4241\n",
       "2  54404  78.010880  41.985297     7445\n",
       "3  74994  76.775460  41.428476     7669\n",
       "4  56143  76.774029  41.546253      978"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = pd.read_json(\"04 Data/stat/player_all_stat.json\")\n",
    "stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>nr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4563</th>\n",
       "      <td>30505</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4476</th>\n",
       "      <td>78140</td>\n",
       "      <td>117.200000</td>\n",
       "      <td>39.448701</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4540</th>\n",
       "      <td>50172</td>\n",
       "      <td>116.666667</td>\n",
       "      <td>35.803166</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4485</th>\n",
       "      <td>9797</td>\n",
       "      <td>115.857143</td>\n",
       "      <td>35.324347</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2988</th>\n",
       "      <td>51264</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>35.853870</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4064</th>\n",
       "      <td>34186</td>\n",
       "      <td>28.400000</td>\n",
       "      <td>48.366311</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>38681</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4469</th>\n",
       "      <td>509</td>\n",
       "      <td>20.600000</td>\n",
       "      <td>30.525399</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4590</th>\n",
       "      <td>83958</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4608</th>\n",
       "      <td>79428</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4609 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id        mean        std  nr\n",
       "4563  30505  140.000000   0.000000   1\n",
       "4476  78140  117.200000  39.448701   5\n",
       "4540  50172  116.666667  35.803166   6\n",
       "4485   9797  115.857143  35.324347   7\n",
       "2988  51264  115.000000  35.853870   5\n",
       "...     ...         ...        ...  ..\n",
       "4064  34186   28.400000  48.366311   5\n",
       "4598  38681   23.000000   0.000000   1\n",
       "4469    509   20.600000  30.525399   5\n",
       "4590  83958   10.000000   0.000000   2\n",
       "4608  79428    0.000000   0.000000   1\n",
       "\n",
       "[4609 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.sort_values(by=['mean'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop bad players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>nr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>55302</td>\n",
       "      <td>80.104669</td>\n",
       "      <td>42.997449</td>\n",
       "      <td>9382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5148</td>\n",
       "      <td>79.449837</td>\n",
       "      <td>42.014048</td>\n",
       "      <td>2452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>55598</td>\n",
       "      <td>81.008357</td>\n",
       "      <td>42.616551</td>\n",
       "      <td>6701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6170</td>\n",
       "      <td>79.899005</td>\n",
       "      <td>42.884173</td>\n",
       "      <td>5426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>62184</td>\n",
       "      <td>79.131810</td>\n",
       "      <td>42.586806</td>\n",
       "      <td>1138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>82568</td>\n",
       "      <td>79.222222</td>\n",
       "      <td>44.041962</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>8740</td>\n",
       "      <td>81.300000</td>\n",
       "      <td>30.746454</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4601</th>\n",
       "      <td>86397</td>\n",
       "      <td>93.250000</td>\n",
       "      <td>60.395719</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>79771</td>\n",
       "      <td>89.750000</td>\n",
       "      <td>47.470804</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>83899</td>\n",
       "      <td>85.200000</td>\n",
       "      <td>40.646990</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1691 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id       mean        std    nr\n",
       "10    55302  80.104669  42.997449  9382\n",
       "11     5148  79.449837  42.014048  2452\n",
       "20    55598  81.008357  42.616551  6701\n",
       "26     6170  79.899005  42.884173  5426\n",
       "27    62184  79.131810  42.586806  1138\n",
       "...     ...        ...        ...   ...\n",
       "4596  82568  79.222222  44.041962     9\n",
       "4600   8740  81.300000  30.746454    10\n",
       "4601  86397  93.250000  60.395719     8\n",
       "4603  79771  89.750000  47.470804    12\n",
       "4604  83899  85.200000  40.646990    10\n",
       "\n",
       "[1691 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_users = stats.loc[(stats['mean'] > 79) & (stats['nr'] > 5)]\n",
    "good_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DA</th>\n",
       "      <th>DK</th>\n",
       "      <th>DQ</th>\n",
       "      <th>DJ</th>\n",
       "      <th>D10</th>\n",
       "      <th>D9</th>\n",
       "      <th>D8</th>\n",
       "      <th>D7</th>\n",
       "      <th>D6</th>\n",
       "      <th>HA</th>\n",
       "      <th>HK</th>\n",
       "      <th>HQ</th>\n",
       "      <th>HJ</th>\n",
       "      <th>H10</th>\n",
       "      <th>H9</th>\n",
       "      <th>H8</th>\n",
       "      <th>H7</th>\n",
       "      <th>H6</th>\n",
       "      <th>SA</th>\n",
       "      <th>SK</th>\n",
       "      <th>SQ</th>\n",
       "      <th>SJ</th>\n",
       "      <th>S10</th>\n",
       "      <th>S9</th>\n",
       "      <th>S8</th>\n",
       "      <th>S7</th>\n",
       "      <th>S6</th>\n",
       "      <th>CA</th>\n",
       "      <th>CK</th>\n",
       "      <th>CQ</th>\n",
       "      <th>CJ</th>\n",
       "      <th>C10</th>\n",
       "      <th>C9</th>\n",
       "      <th>C8</th>\n",
       "      <th>C7</th>\n",
       "      <th>C6</th>\n",
       "      <th>FH</th>\n",
       "      <th>user</th>\n",
       "      <th>trump</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53248</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4613</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8392</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53076</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>66261</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359800</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>37176</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359811</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7750</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359820</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54390</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359821</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19345</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359822</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7538</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101997 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        DA  DK  DQ  DJ  D10  D9  D8  D7  D6  HA  HK  HQ  HJ  H10  H9  H8  H7  \\\n",
       "0        0   0   0   1    1   0   1   1   0   0   0   0   0    0   0   0   0   \n",
       "1        0   0   0   0    0   0   0   0   1   1   0   0   0    0   1   1   0   \n",
       "4        0   1   0   0    0   0   0   0   1   1   1   1   0    0   0   1   0   \n",
       "5        0   0   1   0    0   0   1   0   1   0   1   1   0    0   1   0   0   \n",
       "10       0   0   0   0    0   0   0   1   0   0   0   0   0    0   0   1   0   \n",
       "...     ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..   \n",
       "359800   1   1   0   0    0   0   1   0   1   0   0   0   0    1   1   0   0   \n",
       "359811   1   1   0   0    0   1   0   0   1   0   0   0   0    0   1   0   0   \n",
       "359820   0   0   0   0    0   1   0   0   0   0   1   0   0    0   0   0   1   \n",
       "359821   1   0   0   0    0   0   0   0   1   1   0   1   0    0   0   1   0   \n",
       "359822   1   1   1   0    0   0   0   0   0   0   0   0   0    0   1   0   0   \n",
       "\n",
       "        H6  SA  SK  SQ  SJ  S10  S9  S8  S7  S6  CA  CK  CQ  CJ  C10  C9  C8  \\\n",
       "0        0   1   0   1   1    0   0   0   0   0   0   0   1   0    0   0   1   \n",
       "1        1   0   0   0   0    1   0   0   1   0   0   0   0   1    0   0   0   \n",
       "4        1   0   0   0   0    0   0   0   1   0   0   0   0   1    0   0   0   \n",
       "5        1   0   0   0   0    0   0   0   0   1   1   0   0   0    0   0   0   \n",
       "10       0   0   1   0   0    1   1   0   1   1   0   0   0   1    0   0   0   \n",
       "...     ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..   \n",
       "359800   0   0   0   0   0    0   1   0   0   0   0   0   1   0    0   0   0   \n",
       "359811   0   1   0   1   1    0   1   0   0   0   0   0   0   0    0   0   0   \n",
       "359820   0   0   1   1   0    1   0   0   1   0   0   0   1   0    0   1   0   \n",
       "359821   0   1   0   0   1    0   0   1   0   0   0   0   0   0    1   0   0   \n",
       "359822   0   0   0   0   0    0   1   1   0   0   1   0   0   0    0   0   1   \n",
       "\n",
       "        C7  C6  FH   user  trump  \n",
       "0        0   0   0  53248      6  \n",
       "1        1   0   0   4613      5  \n",
       "4        0   0   1   8392      4  \n",
       "5        0   0   1  53076      5  \n",
       "10       1   0   1  66261      2  \n",
       "...     ..  ..  ..    ...    ...  \n",
       "359800   0   1   0  37176      6  \n",
       "359811   0   0   0   7750      2  \n",
       "359820   0   0   0  54390      6  \n",
       "359821   0   0   0  19345      2  \n",
       "359822   0   1   1   7538      4  \n",
       "\n",
       "[101997 rows x 39 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[data['user'].isin(good_users['id'])]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "feature_columns = []\n",
    "for color in 'DHSC':\n",
    "    # Jack and nine combination\n",
    "    new_col = '{}_J9'.format(color)\n",
    "    data[new_col]  = data['{}J'.format(color)] & data['{}9'.format(color)]\n",
    "    feature_columns.append(new_col)\n",
    "    \n",
    "    #Ace King and Queen\n",
    "    new_col = '{}_AKQ'.format(color)\n",
    "    data[new_col] = data['{}A'.format(color)] & data['{}K'.format(color)] & data['{}Q'.format(color)]\n",
    "    feature_columns.append(new_col)\n",
    "\n",
    "    #Ace and King\n",
    "    new_col = '{}_AK'.format(color)\n",
    "    data[new_col] = data['{}A'.format(color)] & data['{}K'.format(color)]\n",
    "    feature_columns.append(new_col)\n",
    "\n",
    "    #Ace Jack and Nine\n",
    "    new_col = '{}_AJ9'.format(color)\n",
    "    data[new_col]  = data['{}A'.format(color)] &data['{}J'.format(color)] & data['{}9'.format(color)]\n",
    "    feature_columns.append(new_col)\n",
    "\n",
    "    #Acem Jack, King, Queen\n",
    "    new_col = '{}_AJKQ'.format(color)\n",
    "    data[new_col]  = data['{}A'.format(color)] &data['{}J'.format(color)] & data['{}K'.format(color)] & data['{}Q'.format(color)]\n",
    "    feature_columns.append(new_col)\n",
    "\n",
    "    #Ace, 9, King, Queen\n",
    "    new_col = '{}_A9KQ'.format(color)\n",
    "    data[new_col]  = data['{}A'.format(color)] &data['{}9'.format(color)] & data['{}K'.format(color)] & data['{}Q'.format(color)]\n",
    "    feature_columns.append(new_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        DA  DK  DQ  DJ  D10  D9  D8  D7  D6  HA  HK  HQ  HJ  H10  H9  H8  H7  \\\n",
      "0        0   0   0   1    1   0   1   1   0   0   0   0   0    0   0   0   0   \n",
      "1        0   0   0   0    0   0   0   0   1   1   0   0   0    0   1   1   0   \n",
      "4        0   1   0   0    0   0   0   0   1   1   1   1   0    0   0   1   0   \n",
      "5        0   0   1   0    0   0   1   0   1   0   1   1   0    0   1   0   0   \n",
      "10       0   0   0   0    0   0   0   1   0   0   0   0   0    0   0   1   0   \n",
      "...     ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..   \n",
      "359800   1   1   0   0    0   0   1   0   1   0   0   0   0    1   1   0   0   \n",
      "359811   1   1   0   0    0   1   0   0   1   0   0   0   0    0   1   0   0   \n",
      "359820   0   0   0   0    0   1   0   0   0   0   1   0   0    0   0   0   1   \n",
      "359821   1   0   0   0    0   0   0   0   1   1   0   1   0    0   0   1   0   \n",
      "359822   1   1   1   0    0   0   0   0   0   0   0   0   0    0   1   0   0   \n",
      "\n",
      "        H6  SA  SK  SQ  SJ  S10  S9  S8  S7  S6  CA  CK  CQ  CJ  C10  C9  C8  \\\n",
      "0        0   1   0   1   1    0   0   0   0   0   0   0   1   0    0   0   1   \n",
      "1        1   0   0   0   0    1   0   0   1   0   0   0   0   1    0   0   0   \n",
      "4        1   0   0   0   0    0   0   0   1   0   0   0   0   1    0   0   0   \n",
      "5        1   0   0   0   0    0   0   0   0   1   1   0   0   0    0   0   0   \n",
      "10       0   0   1   0   0    1   1   0   1   1   0   0   0   1    0   0   0   \n",
      "...     ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..   \n",
      "359800   0   0   0   0   0    0   1   0   0   0   0   0   1   0    0   0   0   \n",
      "359811   0   1   0   1   1    0   1   0   0   0   0   0   0   0    0   0   0   \n",
      "359820   0   0   1   1   0    1   0   0   1   0   0   0   1   0    0   1   0   \n",
      "359821   0   1   0   0   1    0   0   1   0   0   0   0   0   0    1   0   0   \n",
      "359822   0   0   0   0   0    0   1   1   0   0   1   0   0   0    0   0   1   \n",
      "\n",
      "        C7  C6  D_J9  D_AKQ  D_AK  D_AJ9  D_AJKQ  D_A9KQ  H_J9  H_AKQ  H_AK  \\\n",
      "0        0   0     0      0     0      0       0       0     0      0     0   \n",
      "1        1   0     0      0     0      0       0       0     0      0     0   \n",
      "4        0   0     0      0     0      0       0       0     0      1     1   \n",
      "5        0   0     0      0     0      0       0       0     0      0     0   \n",
      "10       1   0     0      0     0      0       0       0     0      0     0   \n",
      "...     ..  ..   ...    ...   ...    ...     ...     ...   ...    ...   ...   \n",
      "359800   0   1     0      0     1      0       0       0     0      0     0   \n",
      "359811   0   0     0      0     1      0       0       0     0      0     0   \n",
      "359820   0   0     0      0     0      0       0       0     0      0     0   \n",
      "359821   0   0     0      0     0      0       0       0     0      0     0   \n",
      "359822   0   1     0      1     1      0       0       0     0      0     0   \n",
      "\n",
      "        H_AJ9  H_AJKQ  H_A9KQ  S_J9  S_AKQ  S_AK  S_AJ9  S_AJKQ  S_A9KQ  C_J9  \\\n",
      "0           0       0       0     0      0     0      0       0       0     0   \n",
      "1           0       0       0     0      0     0      0       0       0     0   \n",
      "4           0       0       0     0      0     0      0       0       0     0   \n",
      "5           0       0       0     0      0     0      0       0       0     0   \n",
      "10          0       0       0     0      0     0      0       0       0     0   \n",
      "...       ...     ...     ...   ...    ...   ...    ...     ...     ...   ...   \n",
      "359800      0       0       0     0      0     0      0       0       0     0   \n",
      "359811      0       0       0     1      0     0      1       0       0     0   \n",
      "359820      0       0       0     0      0     0      0       0       0     0   \n",
      "359821      0       0       0     0      0     0      0       0       0     0   \n",
      "359822      0       0       0     0      0     0      0       0       0     0   \n",
      "\n",
      "        C_AKQ  C_AK  C_AJ9  C_AJKQ  C_A9KQ  \n",
      "0           0     0      0       0       0  \n",
      "1           0     0      0       0       0  \n",
      "4           0     0      0       0       0  \n",
      "5           0     0      0       0       0  \n",
      "10          0     0      0       0       0  \n",
      "...       ...   ...    ...     ...     ...  \n",
      "359800      0     0      0       0       0  \n",
      "359811      0     0      0       0       0  \n",
      "359820      0     0      0       0       0  \n",
      "359821      0     0      0       0       0  \n",
      "359822      0     0      0       0       0  \n",
      "\n",
      "[101997 rows x 60 columns]\n"
     ]
    }
   ],
   "source": [
    "x_data = pd.DataFrame(data[cards + feature_columns])\n",
    "print(x_data)\n",
    "\n",
    "y_data = data.trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55266     2\n",
      "231526    1\n",
      "318582    6\n",
      "251538    5\n",
      "118043    1\n",
      "         ..\n",
      "314304    3\n",
      "53946     6\n",
      "149889    3\n",
      "240322    1\n",
      "294276    6\n",
      "Name: trump, Length: 81597, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train_data, y_test_data = train_test_split(x_data, y_data, test_size=0.2, stratify=data.trump, random_state=42)\n",
    "\n",
    "print(y_train_data)\n",
    "#y_train_label = np.argmax(x_train, axis=1)\n",
    "#y_categorical = tf.keras.utils.to_categorical(y_train_label, num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0  1  2  3  4  5  6\n",
      "55266   0  0  1  0  0  0  0\n",
      "231526  0  1  0  0  0  0  0\n",
      "318582  0  0  0  0  0  0  1\n",
      "251538  0  0  0  0  0  1  0\n",
      "118043  0  1  0  0  0  0  0\n",
      "...    .. .. .. .. .. .. ..\n",
      "314304  0  0  0  1  0  0  0\n",
      "53946   0  0  0  0  0  0  1\n",
      "149889  0  0  0  1  0  0  0\n",
      "240322  0  1  0  0  0  0  0\n",
      "294276  0  0  0  0  0  0  1\n",
      "\n",
      "[81597 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "y_train = pd.get_dummies(y_train_data)\n",
    "y_test = pd.get_dummies(y_test_data)\n",
    "print(y_train)\n",
    "input_length = len(cards + feature_columns)\n",
    "print(input_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.8172 - accuracy: 0.3820 - val_loss: 1.7606 - val_accuracy: 0.3901\n",
      "Epoch 2/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.7611 - accuracy: 0.3880 - val_loss: 1.7502 - val_accuracy: 0.3901\n",
      "Epoch 3/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.7525 - accuracy: 0.3880 - val_loss: 1.7432 - val_accuracy: 0.3901\n",
      "Epoch 4/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.7428 - accuracy: 0.3880 - val_loss: 1.7314 - val_accuracy: 0.3901\n",
      "Epoch 5/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.7280 - accuracy: 0.3880 - val_loss: 1.7049 - val_accuracy: 0.3901\n",
      "Epoch 6/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.6983 - accuracy: 0.3884 - val_loss: 1.6528 - val_accuracy: 0.3901\n",
      "Epoch 7/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.6556 - accuracy: 0.3906 - val_loss: 1.5899 - val_accuracy: 0.3930\n",
      "Epoch 8/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.6056 - accuracy: 0.3984 - val_loss: 1.5138 - val_accuracy: 0.4054\n",
      "Epoch 9/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.5528 - accuracy: 0.4242 - val_loss: 1.4305 - val_accuracy: 0.4368\n",
      "Epoch 10/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.4939 - accuracy: 0.4439 - val_loss: 1.3589 - val_accuracy: 0.4796\n",
      "Epoch 11/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.4402 - accuracy: 0.4710 - val_loss: 1.2977 - val_accuracy: 0.5191\n",
      "Epoch 12/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.3984 - accuracy: 0.4884 - val_loss: 1.2411 - val_accuracy: 0.5389\n",
      "Epoch 13/300\n",
      "612/612 [==============================] - 4s 6ms/step - loss: 1.3672 - accuracy: 0.4983 - val_loss: 1.2099 - val_accuracy: 0.5524\n",
      "Epoch 14/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.3392 - accuracy: 0.5089 - val_loss: 1.1796 - val_accuracy: 0.5620\n",
      "Epoch 15/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.3202 - accuracy: 0.5159 - val_loss: 1.1667 - val_accuracy: 0.5663\n",
      "Epoch 16/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.2991 - accuracy: 0.5213 - val_loss: 1.1397 - val_accuracy: 0.5716\n",
      "Epoch 17/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.2804 - accuracy: 0.5302 - val_loss: 1.0988 - val_accuracy: 0.5851\n",
      "Epoch 18/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.2625 - accuracy: 0.5339 - val_loss: 1.0880 - val_accuracy: 0.5860\n",
      "Epoch 19/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.2519 - accuracy: 0.5375 - val_loss: 1.0828 - val_accuracy: 0.5883\n",
      "Epoch 20/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.2450 - accuracy: 0.5380 - val_loss: 1.0608 - val_accuracy: 0.5956\n",
      "Epoch 21/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.2355 - accuracy: 0.5379 - val_loss: 1.0554 - val_accuracy: 0.5937\n",
      "Epoch 22/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.2249 - accuracy: 0.5420 - val_loss: 1.0464 - val_accuracy: 0.5979\n",
      "Epoch 23/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.2160 - accuracy: 0.5432 - val_loss: 1.0463 - val_accuracy: 0.5941\n",
      "Epoch 24/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.2130 - accuracy: 0.5414 - val_loss: 1.0312 - val_accuracy: 0.5988\n",
      "Epoch 25/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.2030 - accuracy: 0.5460 - val_loss: 1.0255 - val_accuracy: 0.6022\n",
      "Epoch 26/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.2015 - accuracy: 0.5453 - val_loss: 1.0314 - val_accuracy: 0.5961\n",
      "Epoch 27/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.1965 - accuracy: 0.5475 - val_loss: 1.0184 - val_accuracy: 0.6008\n",
      "Epoch 28/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.1875 - accuracy: 0.5499 - val_loss: 1.0089 - val_accuracy: 0.6059\n",
      "Epoch 29/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.1867 - accuracy: 0.5497 - val_loss: 1.0118 - val_accuracy: 0.6010\n",
      "Epoch 30/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.1761 - accuracy: 0.5536 - val_loss: 1.0058 - val_accuracy: 0.6020\n",
      "Epoch 31/300\n",
      "612/612 [==============================] - 2s 4ms/step - loss: 1.1735 - accuracy: 0.5539 - val_loss: 1.0037 - val_accuracy: 0.6051\n",
      "Epoch 32/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.1692 - accuracy: 0.5547 - val_loss: 0.9972 - val_accuracy: 0.6071\n",
      "Epoch 33/300\n",
      "612/612 [==============================] - 3s 6ms/step - loss: 1.1629 - accuracy: 0.5538 - val_loss: 0.9984 - val_accuracy: 0.5987\n",
      "Epoch 34/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.1632 - accuracy: 0.5538 - val_loss: 0.9925 - val_accuracy: 0.6059\n",
      "Epoch 35/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.1661 - accuracy: 0.5534 - val_loss: 0.9842 - val_accuracy: 0.6082\n",
      "Epoch 36/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.1572 - accuracy: 0.5557 - val_loss: 0.9911 - val_accuracy: 0.6040\n",
      "Epoch 37/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.1547 - accuracy: 0.5576 - val_loss: 0.9893 - val_accuracy: 0.6012\n",
      "Epoch 38/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.1526 - accuracy: 0.5568 - val_loss: 0.9812 - val_accuracy: 0.6060\n",
      "Epoch 39/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.1517 - accuracy: 0.5590 - val_loss: 0.9805 - val_accuracy: 0.6063\n",
      "Epoch 40/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.1472 - accuracy: 0.5598 - val_loss: 0.9809 - val_accuracy: 0.6088\n",
      "Epoch 41/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.1439 - accuracy: 0.5579 - val_loss: 0.9727 - val_accuracy: 0.6096\n",
      "Epoch 42/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.1439 - accuracy: 0.5584 - val_loss: 0.9727 - val_accuracy: 0.6130\n",
      "Epoch 43/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.1452 - accuracy: 0.5571 - val_loss: 0.9768 - val_accuracy: 0.6038\n",
      "Epoch 44/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.1360 - accuracy: 0.5620 - val_loss: 0.9628 - val_accuracy: 0.6085\n",
      "Epoch 45/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.1363 - accuracy: 0.5611 - val_loss: 0.9637 - val_accuracy: 0.6070\n",
      "Epoch 46/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.1287 - accuracy: 0.5631 - val_loss: 0.9622 - val_accuracy: 0.6155\n",
      "Epoch 47/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.1251 - accuracy: 0.5656 - val_loss: 0.9545 - val_accuracy: 0.6131\n",
      "Epoch 48/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.1238 - accuracy: 0.5612 - val_loss: 0.9664 - val_accuracy: 0.6057\n",
      "Epoch 49/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.1244 - accuracy: 0.5645 - val_loss: 0.9547 - val_accuracy: 0.6085\n",
      "Epoch 50/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.1206 - accuracy: 0.5641 - val_loss: 0.9522 - val_accuracy: 0.6077\n",
      "Epoch 51/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.1191 - accuracy: 0.5647 - val_loss: 0.9589 - val_accuracy: 0.6102\n",
      "Epoch 52/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.1091 - accuracy: 0.5683 - val_loss: 0.9486 - val_accuracy: 0.6108\n",
      "Epoch 53/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.1129 - accuracy: 0.5668 - val_loss: 0.9498 - val_accuracy: 0.6149\n",
      "Epoch 54/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.1144 - accuracy: 0.5669 - val_loss: 0.9517 - val_accuracy: 0.6095\n",
      "Epoch 55/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.1095 - accuracy: 0.5665 - val_loss: 0.9452 - val_accuracy: 0.6148\n",
      "Epoch 56/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.1136 - accuracy: 0.5650 - val_loss: 0.9417 - val_accuracy: 0.6150\n",
      "Epoch 57/300\n",
      "612/612 [==============================] - 4s 6ms/step - loss: 1.1081 - accuracy: 0.5700 - val_loss: 0.9413 - val_accuracy: 0.6159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.1056 - accuracy: 0.5711 - val_loss: 0.9447 - val_accuracy: 0.6172\n",
      "Epoch 59/300\n",
      "612/612 [==============================] - 2s 4ms/step - loss: 1.1058 - accuracy: 0.5689 - val_loss: 0.9461 - val_accuracy: 0.6125\n",
      "Epoch 60/300\n",
      "612/612 [==============================] - 2s 4ms/step - loss: 1.1049 - accuracy: 0.5685 - val_loss: 0.9416 - val_accuracy: 0.6138\n",
      "Epoch 61/300\n",
      "612/612 [==============================] - 2s 4ms/step - loss: 1.1053 - accuracy: 0.5685 - val_loss: 0.9400 - val_accuracy: 0.6155\n",
      "Epoch 62/300\n",
      "612/612 [==============================] - 3s 6ms/step - loss: 1.1032 - accuracy: 0.5707 - val_loss: 0.9402 - val_accuracy: 0.6135\n",
      "Epoch 63/300\n",
      "612/612 [==============================] - 3s 6ms/step - loss: 1.0945 - accuracy: 0.5722 - val_loss: 0.9416 - val_accuracy: 0.6150\n",
      "Epoch 64/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.1014 - accuracy: 0.5696 - val_loss: 0.9467 - val_accuracy: 0.6144\n",
      "Epoch 65/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.1003 - accuracy: 0.5717 - val_loss: 0.9380 - val_accuracy: 0.6172\n",
      "Epoch 66/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.0958 - accuracy: 0.5739 - val_loss: 0.9346 - val_accuracy: 0.6182\n",
      "Epoch 67/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0947 - accuracy: 0.5694 - val_loss: 0.9356 - val_accuracy: 0.6130\n",
      "Epoch 68/300\n",
      "612/612 [==============================] - 2s 4ms/step - loss: 1.0933 - accuracy: 0.5717 - val_loss: 0.9389 - val_accuracy: 0.6152\n",
      "Epoch 69/300\n",
      "612/612 [==============================] - 4s 6ms/step - loss: 1.0897 - accuracy: 0.5755 - val_loss: 0.9385 - val_accuracy: 0.6175\n",
      "Epoch 70/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0915 - accuracy: 0.5746 - val_loss: 0.9326 - val_accuracy: 0.6183\n",
      "Epoch 71/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0879 - accuracy: 0.5736 - val_loss: 0.9401 - val_accuracy: 0.6138\n",
      "Epoch 72/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0890 - accuracy: 0.5740 - val_loss: 0.9333 - val_accuracy: 0.6179\n",
      "Epoch 73/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0889 - accuracy: 0.5729 - val_loss: 0.9282 - val_accuracy: 0.6134\n",
      "Epoch 74/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.0902 - accuracy: 0.5730 - val_loss: 0.9343 - val_accuracy: 0.6144\n",
      "Epoch 75/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.0870 - accuracy: 0.5734 - val_loss: 0.9382 - val_accuracy: 0.6110\n",
      "Epoch 76/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.0870 - accuracy: 0.5728 - val_loss: 0.9295 - val_accuracy: 0.6148\n",
      "Epoch 77/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0862 - accuracy: 0.5754 - val_loss: 0.9346 - val_accuracy: 0.6167\n",
      "Epoch 78/300\n",
      "612/612 [==============================] - 4s 7ms/step - loss: 1.0829 - accuracy: 0.5755 - val_loss: 0.9430 - val_accuracy: 0.6053\n",
      "Epoch 79/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.0825 - accuracy: 0.5767 - val_loss: 0.9347 - val_accuracy: 0.6136\n",
      "Epoch 80/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.0775 - accuracy: 0.5769 - val_loss: 0.9265 - val_accuracy: 0.6184\n",
      "Epoch 81/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0741 - accuracy: 0.5790 - val_loss: 0.9364 - val_accuracy: 0.6219\n",
      "Epoch 82/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0683 - accuracy: 0.5829 - val_loss: 0.9258 - val_accuracy: 0.6232\n",
      "Epoch 83/300\n",
      "612/612 [==============================] - 2s 4ms/step - loss: 1.0721 - accuracy: 0.5781 - val_loss: 0.9303 - val_accuracy: 0.6164\n",
      "Epoch 84/300\n",
      "612/612 [==============================] - 2s 4ms/step - loss: 1.0629 - accuracy: 0.5812 - val_loss: 0.9257 - val_accuracy: 0.6184\n",
      "Epoch 85/300\n",
      "612/612 [==============================] - 2s 4ms/step - loss: 1.0669 - accuracy: 0.5806 - val_loss: 0.9261 - val_accuracy: 0.6264\n",
      "Epoch 86/300\n",
      "612/612 [==============================] - 2s 4ms/step - loss: 1.0592 - accuracy: 0.5789 - val_loss: 0.9269 - val_accuracy: 0.6192\n",
      "Epoch 87/300\n",
      "612/612 [==============================] - 2s 4ms/step - loss: 1.0619 - accuracy: 0.5798 - val_loss: 0.9222 - val_accuracy: 0.6218\n",
      "Epoch 88/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0594 - accuracy: 0.5790 - val_loss: 0.9195 - val_accuracy: 0.6223\n",
      "Epoch 89/300\n",
      "612/612 [==============================] - 2s 4ms/step - loss: 1.0582 - accuracy: 0.5802 - val_loss: 0.9224 - val_accuracy: 0.6231\n",
      "Epoch 90/300\n",
      "612/612 [==============================] - 4s 6ms/step - loss: 1.0583 - accuracy: 0.5801 - val_loss: 0.9293 - val_accuracy: 0.6163\n",
      "Epoch 91/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.0577 - accuracy: 0.5798 - val_loss: 0.9302 - val_accuracy: 0.6220\n",
      "Epoch 92/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.0543 - accuracy: 0.5797 - val_loss: 0.9222 - val_accuracy: 0.6243\n",
      "Epoch 93/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.0490 - accuracy: 0.5811 - val_loss: 0.9225 - val_accuracy: 0.6147\n",
      "Epoch 94/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0518 - accuracy: 0.5820 - val_loss: 0.9164 - val_accuracy: 0.6260\n",
      "Epoch 95/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0513 - accuracy: 0.5811 - val_loss: 0.9278 - val_accuracy: 0.6255\n",
      "Epoch 96/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0513 - accuracy: 0.5802 - val_loss: 0.9218 - val_accuracy: 0.6218\n",
      "Epoch 97/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0502 - accuracy: 0.5837 - val_loss: 0.9219 - val_accuracy: 0.6207\n",
      "Epoch 98/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.0515 - accuracy: 0.5805 - val_loss: 0.9180 - val_accuracy: 0.6183\n",
      "Epoch 99/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0501 - accuracy: 0.5804 - val_loss: 0.9190 - val_accuracy: 0.6213\n",
      "Epoch 100/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0514 - accuracy: 0.5779 - val_loss: 0.9219 - val_accuracy: 0.6216\n",
      "Epoch 101/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0441 - accuracy: 0.5809 - val_loss: 0.9130 - val_accuracy: 0.6225\n",
      "Epoch 102/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0452 - accuracy: 0.5827 - val_loss: 0.9224 - val_accuracy: 0.6201\n",
      "Epoch 103/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.0433 - accuracy: 0.5821 - val_loss: 0.9148 - val_accuracy: 0.6215\n",
      "Epoch 104/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0431 - accuracy: 0.5801 - val_loss: 0.9192 - val_accuracy: 0.6194\n",
      "Epoch 105/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0401 - accuracy: 0.5817 - val_loss: 0.9157 - val_accuracy: 0.6268\n",
      "Epoch 106/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0382 - accuracy: 0.5857 - val_loss: 0.9165 - val_accuracy: 0.6206\n",
      "Epoch 107/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0390 - accuracy: 0.5841 - val_loss: 0.9192 - val_accuracy: 0.6265\n",
      "Epoch 108/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.0436 - accuracy: 0.5830 - val_loss: 0.9192 - val_accuracy: 0.6206\n",
      "Epoch 109/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.0397 - accuracy: 0.5817 - val_loss: 0.9200 - val_accuracy: 0.6224\n",
      "Epoch 110/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0375 - accuracy: 0.5850 - val_loss: 0.9182 - val_accuracy: 0.6225\n",
      "Epoch 111/300\n",
      "612/612 [==============================] - 2s 4ms/step - loss: 1.0405 - accuracy: 0.5824 - val_loss: 0.9221 - val_accuracy: 0.6226\n",
      "Epoch 112/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0378 - accuracy: 0.5860 - val_loss: 0.9218 - val_accuracy: 0.6209\n",
      "Epoch 113/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0356 - accuracy: 0.5848 - val_loss: 0.9181 - val_accuracy: 0.6209\n",
      "Epoch 114/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0362 - accuracy: 0.5860 - val_loss: 0.9173 - val_accuracy: 0.6207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/300\n",
      "612/612 [==============================] - 2s 4ms/step - loss: 1.0321 - accuracy: 0.5877 - val_loss: 0.9184 - val_accuracy: 0.6260\n",
      "Epoch 116/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0399 - accuracy: 0.5818 - val_loss: 0.9185 - val_accuracy: 0.6211\n",
      "Epoch 117/300\n",
      "612/612 [==============================] - 2s 4ms/step - loss: 1.0324 - accuracy: 0.5859 - val_loss: 0.9144 - val_accuracy: 0.6223\n",
      "Epoch 118/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0303 - accuracy: 0.5836 - val_loss: 0.9182 - val_accuracy: 0.6192\n",
      "Epoch 119/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0348 - accuracy: 0.5850 - val_loss: 0.9205 - val_accuracy: 0.6213\n",
      "Epoch 120/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0346 - accuracy: 0.5861 - val_loss: 0.9182 - val_accuracy: 0.6241\n",
      "Epoch 121/300\n",
      "612/612 [==============================] - 2s 4ms/step - loss: 1.0364 - accuracy: 0.5843 - val_loss: 0.9230 - val_accuracy: 0.6149\n",
      "Epoch 122/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0325 - accuracy: 0.5850 - val_loss: 0.9218 - val_accuracy: 0.6286\n",
      "Epoch 123/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0258 - accuracy: 0.5865 - val_loss: 0.9179 - val_accuracy: 0.6212\n",
      "Epoch 124/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0335 - accuracy: 0.5845 - val_loss: 0.9197 - val_accuracy: 0.6205\n",
      "Epoch 125/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.0301 - accuracy: 0.5848 - val_loss: 0.9245 - val_accuracy: 0.6224\n",
      "Epoch 126/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0275 - accuracy: 0.5880 - val_loss: 0.9172 - val_accuracy: 0.6244\n",
      "Epoch 127/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0215 - accuracy: 0.5886 - val_loss: 0.9164 - val_accuracy: 0.6223\n",
      "Epoch 128/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0239 - accuracy: 0.5893 - val_loss: 0.9181 - val_accuracy: 0.6204\n",
      "Epoch 129/300\n",
      "612/612 [==============================] - 2s 4ms/step - loss: 1.0230 - accuracy: 0.5871 - val_loss: 0.9230 - val_accuracy: 0.6265\n",
      "Epoch 130/300\n",
      "612/612 [==============================] - 2s 4ms/step - loss: 1.0235 - accuracy: 0.5884 - val_loss: 0.9206 - val_accuracy: 0.6220\n",
      "Epoch 131/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0275 - accuracy: 0.5879 - val_loss: 0.9170 - val_accuracy: 0.6246\n",
      "Epoch 132/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0231 - accuracy: 0.5861 - val_loss: 0.9188 - val_accuracy: 0.6223\n",
      "Epoch 133/300\n",
      "612/612 [==============================] - 2s 4ms/step - loss: 1.0251 - accuracy: 0.5864 - val_loss: 0.9229 - val_accuracy: 0.6231\n",
      "Epoch 134/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0211 - accuracy: 0.5900 - val_loss: 0.9172 - val_accuracy: 0.6268\n",
      "Epoch 135/300\n",
      "612/612 [==============================] - 4s 6ms/step - loss: 1.0220 - accuracy: 0.5897 - val_loss: 0.9260 - val_accuracy: 0.6177\n",
      "Epoch 136/300\n",
      "612/612 [==============================] - 3s 6ms/step - loss: 1.0217 - accuracy: 0.5879 - val_loss: 0.9288 - val_accuracy: 0.6228\n",
      "Epoch 137/300\n",
      "612/612 [==============================] - 4s 6ms/step - loss: 1.0246 - accuracy: 0.5889 - val_loss: 0.9188 - val_accuracy: 0.6215\n",
      "Epoch 138/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0265 - accuracy: 0.5861 - val_loss: 0.9200 - val_accuracy: 0.6244\n",
      "Epoch 139/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.0253 - accuracy: 0.5881 - val_loss: 0.9168 - val_accuracy: 0.6276\n",
      "Epoch 140/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.0229 - accuracy: 0.5858 - val_loss: 0.9198 - val_accuracy: 0.6160\n",
      "Epoch 141/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.0200 - accuracy: 0.5878 - val_loss: 0.9215 - val_accuracy: 0.6273\n",
      "Epoch 142/300\n",
      "612/612 [==============================] - 3s 6ms/step - loss: 1.0182 - accuracy: 0.5880 - val_loss: 0.9230 - val_accuracy: 0.6181\n",
      "Epoch 143/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.0206 - accuracy: 0.5889 - val_loss: 0.9168 - val_accuracy: 0.6227\n",
      "Epoch 144/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.0171 - accuracy: 0.5911 - val_loss: 0.9159 - val_accuracy: 0.6233\n",
      "Epoch 145/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.0182 - accuracy: 0.5923 - val_loss: 0.9252 - val_accuracy: 0.6175\n",
      "Epoch 146/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.0153 - accuracy: 0.5862 - val_loss: 0.9214 - val_accuracy: 0.6238\n",
      "Epoch 147/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.0179 - accuracy: 0.5884 - val_loss: 0.9167 - val_accuracy: 0.6236\n",
      "Epoch 148/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0148 - accuracy: 0.5900 - val_loss: 0.9220 - val_accuracy: 0.6203\n",
      "Epoch 149/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.0117 - accuracy: 0.5894 - val_loss: 0.9246 - val_accuracy: 0.6213\n",
      "Epoch 150/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0151 - accuracy: 0.5879 - val_loss: 0.9243 - val_accuracy: 0.6247\n",
      "Epoch 151/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.0146 - accuracy: 0.5886 - val_loss: 0.9226 - val_accuracy: 0.6240\n",
      "Epoch 152/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.0076 - accuracy: 0.5947 - val_loss: 0.9297 - val_accuracy: 0.6181\n",
      "Epoch 153/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.0091 - accuracy: 0.5905 - val_loss: 0.9252 - val_accuracy: 0.6233\n",
      "Epoch 154/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0079 - accuracy: 0.5918 - val_loss: 0.9189 - val_accuracy: 0.6240\n",
      "Epoch 155/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0155 - accuracy: 0.5895 - val_loss: 0.9244 - val_accuracy: 0.6230\n",
      "Epoch 156/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0093 - accuracy: 0.5896 - val_loss: 0.9226 - val_accuracy: 0.6235\n",
      "Epoch 157/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0101 - accuracy: 0.5891 - val_loss: 0.9180 - val_accuracy: 0.6238\n",
      "Epoch 158/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0109 - accuracy: 0.5887 - val_loss: 0.9235 - val_accuracy: 0.6235\n",
      "Epoch 159/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0093 - accuracy: 0.5921 - val_loss: 0.9190 - val_accuracy: 0.6223\n",
      "Epoch 160/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0072 - accuracy: 0.5877 - val_loss: 0.9266 - val_accuracy: 0.6255\n",
      "Epoch 161/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.0049 - accuracy: 0.5943 - val_loss: 0.9228 - val_accuracy: 0.6241\n",
      "Epoch 162/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0092 - accuracy: 0.5886 - val_loss: 0.9307 - val_accuracy: 0.6228\n",
      "Epoch 163/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0085 - accuracy: 0.5891 - val_loss: 0.9246 - val_accuracy: 0.6195\n",
      "Epoch 164/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0064 - accuracy: 0.5928 - val_loss: 0.9212 - val_accuracy: 0.6233\n",
      "Epoch 165/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0082 - accuracy: 0.5897 - val_loss: 0.9333 - val_accuracy: 0.6231\n",
      "Epoch 166/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0085 - accuracy: 0.5909 - val_loss: 0.9278 - val_accuracy: 0.6183\n",
      "Epoch 167/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.0026 - accuracy: 0.5924 - val_loss: 0.9278 - val_accuracy: 0.6176\n",
      "Epoch 168/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.0068 - accuracy: 0.5905 - val_loss: 0.9251 - val_accuracy: 0.6221\n",
      "Epoch 169/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.0049 - accuracy: 0.5931 - val_loss: 0.9258 - val_accuracy: 0.6196\n",
      "Epoch 170/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0019 - accuracy: 0.5932 - val_loss: 0.9279 - val_accuracy: 0.6246\n",
      "Epoch 171/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0011 - accuracy: 0.5921 - val_loss: 0.9343 - val_accuracy: 0.6202\n",
      "Epoch 172/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0039 - accuracy: 0.5919 - val_loss: 0.9283 - val_accuracy: 0.6191\n",
      "Epoch 173/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0049 - accuracy: 0.5900 - val_loss: 0.9368 - val_accuracy: 0.6238\n",
      "Epoch 174/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0057 - accuracy: 0.5916 - val_loss: 0.9341 - val_accuracy: 0.6219\n",
      "Epoch 175/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.9982 - accuracy: 0.5938 - val_loss: 0.9264 - val_accuracy: 0.6199\n",
      "Epoch 176/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0052 - accuracy: 0.5933 - val_loss: 0.9318 - val_accuracy: 0.6238\n",
      "Epoch 177/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0042 - accuracy: 0.5911 - val_loss: 0.9368 - val_accuracy: 0.6286\n",
      "Epoch 178/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.9971 - accuracy: 0.5941 - val_loss: 0.9275 - val_accuracy: 0.6218\n",
      "Epoch 179/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.0040 - accuracy: 0.5898 - val_loss: 0.9347 - val_accuracy: 0.6215\n",
      "Epoch 180/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 0.9964 - accuracy: 0.5925 - val_loss: 0.9310 - val_accuracy: 0.6151\n",
      "Epoch 181/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.9995 - accuracy: 0.5905 - val_loss: 0.9399 - val_accuracy: 0.6178\n",
      "Epoch 182/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.9989 - accuracy: 0.5913 - val_loss: 0.9375 - val_accuracy: 0.6187\n",
      "Epoch 183/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.9990 - accuracy: 0.5905 - val_loss: 0.9320 - val_accuracy: 0.6225\n",
      "Epoch 184/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.9960 - accuracy: 0.5918 - val_loss: 0.9313 - val_accuracy: 0.6235\n",
      "Epoch 185/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.9952 - accuracy: 0.5926 - val_loss: 0.9368 - val_accuracy: 0.6229\n",
      "Epoch 186/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.9960 - accuracy: 0.5929 - val_loss: 0.9491 - val_accuracy: 0.6239\n",
      "Epoch 187/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.9979 - accuracy: 0.5930 - val_loss: 0.9342 - val_accuracy: 0.6239\n",
      "Epoch 188/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.9963 - accuracy: 0.5913 - val_loss: 0.9324 - val_accuracy: 0.6154\n",
      "Epoch 189/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.9978 - accuracy: 0.5912 - val_loss: 0.9361 - val_accuracy: 0.6220\n",
      "Epoch 190/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.9982 - accuracy: 0.5923 - val_loss: 0.9342 - val_accuracy: 0.6225\n",
      "Epoch 191/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.9966 - accuracy: 0.5916 - val_loss: 0.9394 - val_accuracy: 0.6196\n",
      "Epoch 192/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 0.9968 - accuracy: 0.5937 - val_loss: 0.9303 - val_accuracy: 0.6208\n",
      "Epoch 193/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.9933 - accuracy: 0.5932 - val_loss: 0.9459 - val_accuracy: 0.6161\n",
      "Epoch 194/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 0.9928 - accuracy: 0.5928 - val_loss: 0.9354 - val_accuracy: 0.6216\n",
      "Epoch 195/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.9896 - accuracy: 0.5973 - val_loss: 0.9330 - val_accuracy: 0.6230\n",
      "Epoch 196/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.9953 - accuracy: 0.5933 - val_loss: 0.9345 - val_accuracy: 0.6206\n",
      "Epoch 197/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.9940 - accuracy: 0.5947 - val_loss: 0.9384 - val_accuracy: 0.6208\n",
      "Epoch 198/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.9912 - accuracy: 0.5955 - val_loss: 0.9338 - val_accuracy: 0.6168\n",
      "Epoch 199/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 0.9895 - accuracy: 0.5948 - val_loss: 0.9378 - val_accuracy: 0.6180\n",
      "Epoch 200/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 0.9952 - accuracy: 0.5932 - val_loss: 0.9359 - val_accuracy: 0.6211\n",
      "Epoch 201/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.9888 - accuracy: 0.5966 - val_loss: 0.9402 - val_accuracy: 0.6226\n",
      "Epoch 202/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.9860 - accuracy: 0.5972 - val_loss: 0.9375 - val_accuracy: 0.6148\n",
      "Epoch 203/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 0.9865 - accuracy: 0.5982 - val_loss: 0.9388 - val_accuracy: 0.6213\n",
      "Epoch 204/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 0.9872 - accuracy: 0.5937 - val_loss: 0.9400 - val_accuracy: 0.6151\n",
      "Epoch 205/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 0.9807 - accuracy: 0.5987 - val_loss: 0.9348 - val_accuracy: 0.6215\n",
      "Epoch 206/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 0.9787 - accuracy: 0.6009 - val_loss: 0.9476 - val_accuracy: 0.6275\n",
      "Epoch 207/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.9778 - accuracy: 0.5990 - val_loss: 0.9386 - val_accuracy: 0.6201\n",
      "Epoch 208/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.9785 - accuracy: 0.5990 - val_loss: 0.9342 - val_accuracy: 0.6206\n",
      "Epoch 209/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 0.9767 - accuracy: 0.6008 - val_loss: 0.9375 - val_accuracy: 0.6236\n",
      "Epoch 210/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 0.9755 - accuracy: 0.6005 - val_loss: 0.9389 - val_accuracy: 0.6235\n",
      "Epoch 211/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 0.9728 - accuracy: 0.6016 - val_loss: 0.9420 - val_accuracy: 0.6194\n",
      "Epoch 212/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 0.9736 - accuracy: 0.5997 - val_loss: 0.9358 - val_accuracy: 0.6197\n",
      "Epoch 213/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 0.9716 - accuracy: 0.6001 - val_loss: 0.9354 - val_accuracy: 0.6219\n",
      "Epoch 214/300\n",
      "612/612 [==============================] - 4s 6ms/step - loss: 0.9725 - accuracy: 0.5994 - val_loss: 0.9443 - val_accuracy: 0.6185\n",
      "Epoch 215/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.9719 - accuracy: 0.6021 - val_loss: 0.9625 - val_accuracy: 0.6251\n",
      "Epoch 216/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 0.9726 - accuracy: 0.6010 - val_loss: 0.9479 - val_accuracy: 0.6234\n",
      "Epoch 217/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.9678 - accuracy: 0.6020 - val_loss: 0.9403 - val_accuracy: 0.6240\n",
      "Epoch 218/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 0.9688 - accuracy: 0.6032 - val_loss: 0.9381 - val_accuracy: 0.6204\n",
      "Epoch 219/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.9707 - accuracy: 0.6012 - val_loss: 0.9276 - val_accuracy: 0.6247\n",
      "Epoch 220/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 0.9660 - accuracy: 0.6007 - val_loss: 0.9356 - val_accuracy: 0.6239\n",
      "Epoch 221/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.9708 - accuracy: 0.6013 - val_loss: 0.9418 - val_accuracy: 0.6250\n",
      "Epoch 222/300\n",
      "612/612 [==============================] - 2s 4ms/step - loss: 0.9649 - accuracy: 0.6016 - val_loss: 0.9466 - val_accuracy: 0.6215\n",
      "Epoch 223/300\n",
      "612/612 [==============================] - 2s 4ms/step - loss: 0.9660 - accuracy: 0.6020 - val_loss: 0.9439 - val_accuracy: 0.6162\n",
      "Epoch 224/300\n",
      "612/612 [==============================] - 2s 4ms/step - loss: 0.9674 - accuracy: 0.6011 - val_loss: 0.9393 - val_accuracy: 0.6219\n",
      "Epoch 225/300\n",
      "612/612 [==============================] - 2s 4ms/step - loss: 0.9652 - accuracy: 0.6009 - val_loss: 0.9467 - val_accuracy: 0.6088\n",
      "Epoch 226/300\n",
      "612/612 [==============================] - 2s 4ms/step - loss: 0.9644 - accuracy: 0.6023 - val_loss: 0.9406 - val_accuracy: 0.6228\n",
      "Epoch 227/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "612/612 [==============================] - 2s 4ms/step - loss: 0.9598 - accuracy: 0.6029 - val_loss: 0.9415 - val_accuracy: 0.6184\n",
      "Epoch 228/300\n",
      "612/612 [==============================] - 2s 4ms/step - loss: 0.9609 - accuracy: 0.6024 - val_loss: 0.9373 - val_accuracy: 0.6228\n",
      "Epoch 229/300\n",
      "612/612 [==============================] - 2s 4ms/step - loss: 0.9666 - accuracy: 0.6005 - val_loss: 0.9477 - val_accuracy: 0.6201\n",
      "Epoch 230/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.9657 - accuracy: 0.6011 - val_loss: 0.9458 - val_accuracy: 0.6211\n",
      "Epoch 231/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.9635 - accuracy: 0.6032 - val_loss: 0.9388 - val_accuracy: 0.6190\n",
      "Epoch 232/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.9612 - accuracy: 0.6032 - val_loss: 0.9561 - val_accuracy: 0.6224\n",
      "Epoch 233/300\n",
      "612/612 [==============================] - 2s 4ms/step - loss: 0.9577 - accuracy: 0.6038 - val_loss: 0.9450 - val_accuracy: 0.6166\n",
      "Epoch 234/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.9579 - accuracy: 0.6031 - val_loss: 0.9441 - val_accuracy: 0.6201\n",
      "Epoch 235/300\n",
      "612/612 [==============================] - 2s 4ms/step - loss: 0.9585 - accuracy: 0.6037 - val_loss: 0.9535 - val_accuracy: 0.6192\n",
      "Epoch 236/300\n",
      "612/612 [==============================] - 2s 4ms/step - loss: 0.9589 - accuracy: 0.6029 - val_loss: 0.9399 - val_accuracy: 0.6190\n",
      "Epoch 237/300\n",
      "612/612 [==============================] - 2s 4ms/step - loss: 0.9624 - accuracy: 0.6018 - val_loss: 0.9567 - val_accuracy: 0.6215\n",
      "Epoch 238/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 0.9596 - accuracy: 0.6029 - val_loss: 0.9445 - val_accuracy: 0.6192\n",
      "Epoch 239/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 0.9623 - accuracy: 0.6030 - val_loss: 0.9483 - val_accuracy: 0.6241\n",
      "Epoch 240/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 0.9588 - accuracy: 0.6038 - val_loss: 0.9533 - val_accuracy: 0.6248\n",
      "Epoch 241/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 0.9580 - accuracy: 0.6029 - val_loss: 0.9475 - val_accuracy: 0.6216\n",
      "Epoch 242/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 0.9574 - accuracy: 0.6042 - val_loss: 0.9674 - val_accuracy: 0.6206\n",
      "Epoch 243/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 0.9576 - accuracy: 0.6026 - val_loss: 0.9565 - val_accuracy: 0.6227\n",
      "Epoch 244/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 0.9539 - accuracy: 0.6045 - val_loss: 0.9659 - val_accuracy: 0.6258\n",
      "Epoch 245/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 0.9589 - accuracy: 0.6034 - val_loss: 0.9482 - val_accuracy: 0.6183\n",
      "Epoch 246/300\n",
      "612/612 [==============================] - 4s 6ms/step - loss: 0.9570 - accuracy: 0.6032 - val_loss: 0.9505 - val_accuracy: 0.6231\n",
      "Epoch 247/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 0.9509 - accuracy: 0.6048 - val_loss: 0.9568 - val_accuracy: 0.6209\n",
      "Epoch 248/300\n",
      "612/612 [==============================] - 3s 6ms/step - loss: 0.9530 - accuracy: 0.6026 - val_loss: 0.9536 - val_accuracy: 0.6219\n",
      "Epoch 249/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 0.9552 - accuracy: 0.6044 - val_loss: 0.9531 - val_accuracy: 0.6205\n",
      "Epoch 250/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 0.9550 - accuracy: 0.6017 - val_loss: 0.9773 - val_accuracy: 0.6235\n",
      "Epoch 251/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 0.9546 - accuracy: 0.6046 - val_loss: 0.9621 - val_accuracy: 0.6249\n",
      "Epoch 252/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.9518 - accuracy: 0.6044 - val_loss: 0.9479 - val_accuracy: 0.6220\n",
      "Epoch 253/300\n",
      "612/612 [==============================] - 5s 8ms/step - loss: 0.9533 - accuracy: 0.6051 - val_loss: 0.9653 - val_accuracy: 0.6263\n",
      "Epoch 254/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 0.9504 - accuracy: 0.6046 - val_loss: 0.9598 - val_accuracy: 0.6232\n",
      "Epoch 255/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.9518 - accuracy: 0.6059 - val_loss: 0.9624 - val_accuracy: 0.6227\n",
      "Epoch 256/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.9563 - accuracy: 0.6028 - val_loss: 0.9553 - val_accuracy: 0.6191\n",
      "Epoch 257/300\n",
      "612/612 [==============================] - 3s 6ms/step - loss: 0.9503 - accuracy: 0.6062 - val_loss: 0.9614 - val_accuracy: 0.6179\n",
      "Epoch 258/300\n",
      "612/612 [==============================] - 3s 6ms/step - loss: 0.9503 - accuracy: 0.6051 - val_loss: 0.9626 - val_accuracy: 0.6199\n",
      "Epoch 259/300\n",
      "612/612 [==============================] - 4s 6ms/step - loss: 0.9499 - accuracy: 0.6059 - val_loss: 0.9625 - val_accuracy: 0.6190\n",
      "Epoch 260/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 0.9525 - accuracy: 0.6040 - val_loss: 0.9705 - val_accuracy: 0.6227\n",
      "Epoch 261/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.9473 - accuracy: 0.6067 - val_loss: 0.9714 - val_accuracy: 0.6245\n",
      "Epoch 262/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.9520 - accuracy: 0.6049 - val_loss: 0.9849 - val_accuracy: 0.6160\n",
      "Epoch 263/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 0.9467 - accuracy: 0.6070 - val_loss: 0.9611 - val_accuracy: 0.6216\n",
      "Epoch 264/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.9489 - accuracy: 0.6050 - val_loss: 0.9909 - val_accuracy: 0.6251\n",
      "Epoch 265/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.9475 - accuracy: 0.6048 - val_loss: 0.9813 - val_accuracy: 0.6225\n",
      "Epoch 266/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 0.9472 - accuracy: 0.6051 - val_loss: 0.9671 - val_accuracy: 0.6202\n",
      "Epoch 267/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 0.9452 - accuracy: 0.6067 - val_loss: 0.9793 - val_accuracy: 0.6243\n",
      "Epoch 268/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 0.9492 - accuracy: 0.6034 - val_loss: 0.9581 - val_accuracy: 0.6175\n",
      "Epoch 269/300\n",
      "612/612 [==============================] - 4s 6ms/step - loss: 0.9417 - accuracy: 0.6084 - val_loss: 0.9948 - val_accuracy: 0.6247\n",
      "Epoch 270/300\n",
      "612/612 [==============================] - 4s 6ms/step - loss: 0.9512 - accuracy: 0.6041 - val_loss: 0.9765 - val_accuracy: 0.6244\n",
      "Epoch 271/300\n",
      "612/612 [==============================] - 4s 6ms/step - loss: 0.9477 - accuracy: 0.6062 - val_loss: 0.9678 - val_accuracy: 0.6190\n",
      "Epoch 272/300\n",
      "612/612 [==============================] - 4s 6ms/step - loss: 0.9489 - accuracy: 0.6045 - val_loss: 0.9685 - val_accuracy: 0.6213\n",
      "Epoch 273/300\n",
      "612/612 [==============================] - 3s 6ms/step - loss: 0.9439 - accuracy: 0.6059 - val_loss: 0.9785 - val_accuracy: 0.6223\n",
      "Epoch 274/300\n",
      "612/612 [==============================] - 4s 6ms/step - loss: 0.9468 - accuracy: 0.6038 - val_loss: 0.9735 - val_accuracy: 0.6197\n",
      "Epoch 275/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 0.9494 - accuracy: 0.6058 - val_loss: 0.9679 - val_accuracy: 0.6204\n",
      "Epoch 276/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 0.9447 - accuracy: 0.6053 - val_loss: 0.9923 - val_accuracy: 0.6241\n",
      "Epoch 277/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 0.9430 - accuracy: 0.6041 - val_loss: 0.9969 - val_accuracy: 0.6201\n",
      "Epoch 278/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 0.9453 - accuracy: 0.6044 - val_loss: 0.9868 - val_accuracy: 0.6227\n",
      "Epoch 279/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 0.9471 - accuracy: 0.6048 - val_loss: 1.0078 - val_accuracy: 0.6228\n",
      "Epoch 280/300\n",
      "612/612 [==============================] - 4s 6ms/step - loss: 0.9437 - accuracy: 0.6058 - val_loss: 0.9742 - val_accuracy: 0.6200\n",
      "Epoch 281/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 0.9450 - accuracy: 0.6037 - val_loss: 0.9838 - val_accuracy: 0.6206\n",
      "Epoch 282/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 0.9452 - accuracy: 0.6061 - val_loss: 0.9780 - val_accuracy: 0.6216\n",
      "Epoch 283/300\n",
      "612/612 [==============================] - 4s 6ms/step - loss: 0.9396 - accuracy: 0.6087 - val_loss: 0.9811 - val_accuracy: 0.6231\n",
      "Epoch 284/300\n",
      "612/612 [==============================] - 3s 6ms/step - loss: 0.9439 - accuracy: 0.6064 - val_loss: 0.9853 - val_accuracy: 0.6228\n",
      "Epoch 285/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 0.9391 - accuracy: 0.6077 - val_loss: 0.9941 - val_accuracy: 0.6232\n",
      "Epoch 286/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 0.9392 - accuracy: 0.6085 - val_loss: 0.9724 - val_accuracy: 0.6149\n",
      "Epoch 287/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 0.9432 - accuracy: 0.6065 - val_loss: 0.9964 - val_accuracy: 0.6221\n",
      "Epoch 288/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 0.9421 - accuracy: 0.6074 - val_loss: 0.9949 - val_accuracy: 0.6189\n",
      "Epoch 289/300\n",
      "612/612 [==============================] - 2s 4ms/step - loss: 0.9430 - accuracy: 0.6048 - val_loss: 0.9837 - val_accuracy: 0.6246\n",
      "Epoch 290/300\n",
      "612/612 [==============================] - 2s 4ms/step - loss: 0.9417 - accuracy: 0.6056 - val_loss: 1.0000 - val_accuracy: 0.6215\n",
      "Epoch 291/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 0.9406 - accuracy: 0.6060 - val_loss: 0.9816 - val_accuracy: 0.6213\n",
      "Epoch 292/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.9447 - accuracy: 0.6057 - val_loss: 0.9719 - val_accuracy: 0.6209\n",
      "Epoch 293/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 0.9405 - accuracy: 0.6058 - val_loss: 0.9989 - val_accuracy: 0.6233\n",
      "Epoch 294/300\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 0.9380 - accuracy: 0.6091 - val_loss: 0.9901 - val_accuracy: 0.6250\n",
      "Epoch 295/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.9431 - accuracy: 0.6067 - val_loss: 0.9861 - val_accuracy: 0.6217\n",
      "Epoch 296/300\n",
      "612/612 [==============================] - 2s 4ms/step - loss: 0.9418 - accuracy: 0.6078 - val_loss: 0.9809 - val_accuracy: 0.6185\n",
      "Epoch 297/300\n",
      "612/612 [==============================] - 2s 4ms/step - loss: 0.9370 - accuracy: 0.6072 - val_loss: 0.9790 - val_accuracy: 0.6175\n",
      "Epoch 298/300\n",
      "612/612 [==============================] - 2s 4ms/step - loss: 0.9358 - accuracy: 0.6084 - val_loss: 0.9778 - val_accuracy: 0.6169\n",
      "Epoch 299/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.9394 - accuracy: 0.6077 - val_loss: 1.0149 - val_accuracy: 0.6245\n",
      "Epoch 300/300\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.9360 - accuracy: 0.6093 - val_loss: 0.9849 - val_accuracy: 0.6211\n"
     ]
    }
   ],
   "source": [
    "input_length = len(cards + feature_columns)\n",
    "print(input_length)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(input_length, activation='relu', input_shape=[input_length]))\n",
    "model.add(keras.layers.Dense(80, activation='relu'))\n",
    "model.add(keras.layers.Dense(40, activation='relu'))\n",
    "model.add(keras.layers.Dense(36, activation='relu'))\n",
    "model.add(keras.layers.Dense(36, activation='relu'))\n",
    "model.add(keras.layers.Dense(14, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Dense(7, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, validation_split=0.25, epochs=300, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "638/638 [==============================] - 3s 4ms/step - loss: 0.9710 - accuracy: 0.6204\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9710139036178589, 0.6203921437263489]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1cd9d314880>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3yV1f3A8c/JzV5kJ5AEEiDsPQVUhiIoIg4cWCvuVbVq66itVWvbX23rqMVWreJW3AtxgKIoigzZI8wACSF7JzfJvTm/P87N5IbchNwk5H7fr1deN/e5zzjPHed71nMepbVGCCGEaMqrsxMghBCia5IAIYQQwikJEEIIIZySACGEEMIpCRBCCCGckgAhhBDCKQkQQgghnJIAIQSglPpGKVWglPLr7LQI0VVIgBAeTymVBJwGaOC8Djyud0cdS4i2kAAhBFwJrAFeAhbWLlRKJSql3ldK5Sil8pRSixq8dr1SaqdSqkQptUMpNcaxXCul+jdY7yWl1J8d/09TSqUrpe5VSh0FXlRKhSulljqOUeD4P6HB9hFKqReVUkccr3/oWL5NKTW3wXo+SqlcpdQot71LwuNIgBDCBIjXHX+zlFKxSikLsBQ4CCQB8cASAKXUxcBDju1CMbWOPBePFQdEAH2AGzC/wRcdz3sDFcCiBuu/CgQCQ4EY4AnH8leAKxqsdw6QqbXe5GI6hGiRkrmYhCdTSp0KrAR6aq1zlVK7gGcxNYqPHcttTbb5Alimtf6Xk/1pIEVrvdfx/CUgXWv9B6XUNOBLIFRrbW0mPaOAlVrrcKVUTyADiNRaFzRZrxeQCsRrrYuVUu8Ca7XWf2/zmyFEE1KDEJ5uIfCl1jrX8fwNx7JE4GDT4OCQCOxr4/FyGgYHpVSgUupZpdRBpVQxsAoIc9RgEoH8psEBQGt9BFgNXKSUCgPOxtSAhGg30kkmPJZSKgC4BLA4+gQA/IAwIAvorZTydhIkDgP9mtltOaZJqFYckN7gedMq+2+AgcBErfVRRw1iI6Acx4lQSoVprQudHOtl4DrM7/hHrXVG82crROtJDUJ4svMBOzAEGOX4Gwx853gtE/ibUipIKeWvlJri2O554LdKqbHK6K+U6uN4bRNwuVLKopSaDUxtIQ0hmH6HQqVUBPBg7Qta60zgM+A/js5sH6XU6Q22/RAYA/wa0ychRLuSACE82ULgRa31Ia310do/TCfxAmAu0B84hKkFXAqgtX4H+AumOaoEk1FHOPb5a8d2hcAvHK8dz5NAAJCL6ff4vMnrvwSqgV1ANnBH7Qta6wrgPSAZeL+V5y5Ei6STWoiTmFLqj8AArfUVLa4sRCtJH4QQJylHk9S1mFqGEO1OmpiEOAkppa7HdGJ/prVe1dnpEd2TNDEJIYRwSmoQQgghnOpWfRBRUVE6KSmps5MhhBAnjQ0bNuRqraOdvdatAkRSUhLr16/v7GQIIcRJQyl1sLnXpIlJCCGEUxIghBBCOCUBQgghhFPdqg/CmerqatLT07Fanc6u3K34+/uTkJCAj49PZydFCNENdPsAkZ6eTkhICElJSSilOjs5bqO1Ji8vj/T0dJKTkzs7OUKIbqDbNzFZrVYiIyO7dXAAUEoRGRnpETUlIUTH6PYBAuj2waGWp5ynEKJjeESAEKLOoZ/gSDe+bXPa6u59fqJDSYBwo7y8PEaNGsWoUaOIi4sjPj6+7nlVVdVxt12/fj233357B6X0JFFjP/F9LPstfHav6+s7m6ssYwN88Xsoy4Odn5x4mtqL1vDetfD57zr2uOX5sOweqCzt2OMKt5MA4UaRkZFs2rSJTZs2cdNNN3HnnXfWPff19cVmc3a7Y2PcuHE89dRTHZjadnZ0Kyy7G2pqml/HboNt70PJ0ebXqVVRCI8mm/XfuAwO/tD8uofXQlEzd98sOQrZO5xn/OtegM/vb7xs2d3w2KDGy5Y/CD8ugu8fh7eugNLsltPviuO9V67I3Q0lmea9P9F9tcaupbD2WTjQBSeVrSyBovTjr5O90wRVe/O/R08lAaKDXXXVVdx1111Mnz6de++9l7Vr1zJ58mRGjx7N5MmTSU1NBeCbb77h3HPPBeChhx7immuuYdq0afTt2/fkCBxb3oa1z0H+fuevaw17l8O7V8NjA82P9HiOboXKIlj9JOz+zOzfGVsVvHI+LH/g2Ndq7FCeC5XFUJxRv8zmqM1teMlkdPn7IXePyWTX/c9kupUlZp2cVEj7zvx/eK15bO4ca/e/69OWS9fFmfD4IPj+ieOvB1CQVp+ehvZ/Yx6rSqCw2dkT2t+RjeYxe0fz69gq4f0b6tcFSN9gznv1vyBvX/ukJW21+av17OnwxFDn6+btg59fhTX/MX97vmh+v7UFjvJ8+PBXUJLV+PXUz8z5tNfs2MWZUJbbeNmOj2DzksbLqitMmtyk2w9zbejhT7az40hxu+5zSK9QHpzbzBewGbt372bFihVYLBaKi4tZtWoV3t7erFixgvvvv5/33nvvmG127drFypUrKSkpYeDAgdx8881d73oHe7UpTfeIN6VZgOztENXf8boNLN6w9V14/3qY3KAJbdPrcNafm993bQDJ3GweMzY4Xy9zM1SXwf5vzY+1tuP+nashOAZ0Tf3+QnrCy+eZ9Rd+AlnbQdvhuelmvXlP1+83/wD0HGFqGXXH2lT/Wuwwkyn7hcBXj0DsUJh0qzmvT243x7rhG0j7Hn5+GcZdYzKAzE0QlgTWQijNghUPQWAkjLkSMrcAGmKHg5dX/Xv43DQYcj7MfRJ+WAQRyTBojgkQXj5QU20CakST4c5Z201Gd3QL7P4C+kyGmQ83/543fP+OpzbTz9llAsHa58DLG8ZeBT4B9etsecv89Zlizv+9a+v3kbEBLjnB22p/+3dY+RfwC4XfpEJFQX3wLskC3yDwCzbPi9LhpTkm+Hv7m2XrnoeB5xx7zl/9Cb57DG7+0RRqNr0GvoFwys3ms5j5iPmMAeYvhmEX1W9rq4SXzoXJt8GQ845Ns7UYLD4mkw8IM2kEePMys/y6FfXvz7vXmM934Nng38Msf/daSP0UHsg167czjwoQXcXFF1+MxWIBoKioiIULF7Jnzx6UUlRXVzvdZs6cOfj5+eHn50dMTAxZWVkkJCR0ZLKPr7oC/jMJCg7AH7JNSRtMphTR11ThM36G29bXZwy7PweLH/SdCts+gDP/VJ8RlmbD+hdNRhIcfWzpNGs7/PSsWV5RAOOvh+TT4KCj9Fiea37wA2aZjHj7+8dun7MLDn5vnn90qwkOYDJrMCXeWmv+a5anfQ99TjXb2R01jx0fwYc3mf/HXQtb34atmAx685sQEG4yoq//DBtfBZ/A+uaYwEhHCVBD70nmtY9vMwFq6V0mTTMfgSm3mxJvcYY539RlcNYjJqB4+8ON35oAMeISc8yjWxtnSDuXmgzGXuk4bpRZZ+o9plSqlHmva339F9j2Llz3FQRG1C/P2GDe97lPgY+/yQCPbjOvZe+ETW/Al38wz30CYexCU3vK3FK/j4OrzXcBIG44+AabEnh5vsnkvANg6a9NIDm4GnqOggnXO74zX5j3M3FC489Ta/j5FQjrYwL19g8gb2/9629dYWpet6wBL4sJ4tZi8OthaqYxQ2Df1/D8mbDw4/qMOmuHCQ5g3q/amuuGlx3flSL44d/1x9n/jQneu5ZC3+nm+5K+1tREU5eZ85l6H4z+BRQegv/NMM2nNdUmoE691xS0Mjeb70TGBnP+H91m3idroSlgjXf8hlI/NY97lsOgc2hvHhUgWlvSd5egoKC6/x944AGmT5/OBx98QFpaGtOmTXO6jZ+fX93/FovluP0XneLbR01wAJMZ1DZxfPuo+au1okGJNWcXhCfD8Ithz/Xmh3jKzaYTedcn5seXscGURveuAOVlMk7fENOM8tk9EBABaPPDnPmI+WEGRpkAsey35sfUI/7Y9O761JSkB84xP84dH5rliRNNxjL0AvOjm/kwvHMVbH6jftvp98PL59bXRnZ/Vv/a5iUQmmBe+/YfkLUVZjwAq58yGbfygts3wf6V5ocfM8ic27vXmhpV/zNg0TjT96HtJoDs+RLGX2eaS2qVZsGaZ0zaq6odNaFy815mbDCZlpc3TLvXZJ7LH4CoFDjtLvAJMoHm07vgw5tNgAPoNcbUsg79CKv+bpZ99ScTOHqOgOIjJkMDkwke/smUuGuqITzJ1BrX/Ndk+tYikyHGDYPFsyE4zpzLrevN9+GnZyCyP9z0vckMnz0dtr1nPrMxV8LG18wfwI6PTU0koq95n2KHwLVf1r8Xq/9lCiRFh+Gcf5oazHePmXPsPRkO/WAyaYCnRpnPxlZpzssv2LxXV7wPW5aYgJv6GQyfb9bf9HqD78xSyNoGp/zKHGPtc2Z53h5T0Ek6FQ58B6/MM82QY6+qbwqsLRAERMDKv0LvU2DJL0w6JtwAa542tazHBzf+nr57DUQPNjXx+YvhuydMIBx/rflcvf3BZjXvlRsChPRBdLKioiLi400G9tJLL3VuYtqqxg6b3jQ/eDCZra4xmSGYjOeOreb/be+ZkqXF1zzvkWAy42EXwco/m6r1pteg/5kw4jLTLpz6qSn59p1mthm70DwGxcDd++D6lSYz/OR2SF8HQ883pbfI/nB4jTmmavBVH3SuyTC8/eHcx2Huv+pfW7DE7G/OY3DHFpO2IMdU+ZEpMO1+0zQTHNf4PUg5y5xXdRnEj4FRC0xwCIqB0VeYZTU2iBsBIbEw8jITHMCc6z0HzA/c2w9GXm5qJ9GDYeQCkxHv+RKqSs1faAKgzPvl7Q8z/gDF6aZknXSqKd1H9TfvI5gMOH+/yYiGXQQDZ5tgAaZmETfc7Oe5qfDEMFNKDk2AYfNhw4umGaUo3QS5Wiv/avqD1jia4WrTnJsKE240gWPfSvj0N2Z50SFz7oERppYDMGC2eYwbAWG9TdAAkwE2VFkMH/0KXp5rCgZHNpna4ep/mfP66pH6jLzvNDj7URNAUXDhc/XNMSE9TaYaEG6C2sQbYdrvTK0itCdM/jWExptCRVmeOd8NL5t0hiebQgXAKTeZ9xLqv1fRA817X3DABIeeo2Dj62ab+LGOdQbDvEXms1o03gTcS1+F2X81NeDcBjUelPle9kg0hZ+ECTDkAkfT4ybzmRalm+DgG2Jq0rbjj4xsC4+qQXRF99xzDwsXLuTxxx9nxowZnZuYyhJA1bfTFmeapoeQuONuxv5voPQozF5sOvC2OZpzeo02pdlpvzMZQHiSqeb3mWSakHJ2mR+kxQcufN40UaR9Z0rx8xebUqiXtzn+d/+EfjPg1DvNDy5lpvkRenmZppw7tpp9luVAzGDTF1BRAI8NNiXXGb83pWUwmcaRjWad2nO77itz/oERjZtUwJRcy3JMzWHYhWZZaC8oOVJfm0k5C6rKTBNCr1EwZqHJjCbeaI4RP9bUGvpMcf4eejUIYCMvMyX4oReYwPLjIvj6EROAvHxMAKwsNhlp9CCYcqcpufYabd7L3hNNIFjxkGm22fCieR8Hz60/RqQjQGi7yVT7TDEZtLabpr/hF8M5/zAl3dqa2OY3TM0h9TMT/MBkgAERprR85GdIPh1GXW5qIT89Y97nniNNhtZzhON7MQbO/68JjGC+Y70nmxJ8UyG9TIGgohB++q9ZZq80gQdMoFJeJg3e/qZQEJViaibWIghLNM1Hh36Ey16HmKGmmSZ3D0T2c7wX/eo/g2EXmlrQ27+sb64ceiFsfcdk/iG9TKY99R4TZMDUJGKHmoIDmPM690l4eqKpQc1fbGo0w+abZsTBc00/ydR7zG8CTJqry+rPO3aoeU/HXgXVVvMeeXnBiItNE96Gl0wQBrj4JfPb8Gr/8r4EiA7y0EMPOV0+adIkdu/eXff8kUceAWDatGl1zU1Nt922bVvbEpG13ZTYa0tUDR1YZUpog841P6QNL5sSeexw0+xRlA7zXzh2O4CdH5uMcuAciH3aBAWLn/niHlpjMnMwJdWCNFMaytrmCBC9zGteXqYpZskC08wEJp3nO0qoA2ab7X0cHYp9pzVOg2+QCRQNO2YDwuGy10wpvm69YLNu0qmNt08Y1/z7FtHXlOIbbhPaCzIw/R6py8wPtOhwfZt5UBSc+WD9+okTzWPyac0fp+54yXDTapNx2atNk1DeXkiZBef927wvFl+zz7gRpuN/4ceN99FzlHl84SzTBDL6isaBLyTO7Le6DOJGmoxxyh3w5HCT8SVONO/fhOtNaX2F41wmXG/6QmoDRI3NBKaQWLj8rfr995kCV35kSu3efvCfySZ4gMnsRl3eOL19JjkPEEPmwbT7zP9hvU2g++xu8/y035pSeO+JEDXAlKZrO5gbfg96jTFp7jnK9D/4xDVf6Jl4M2z/0HyOo39pviuD55pAt3e5OZZSpkP5nH+YYLn2OROE4seZ93DsVSYw/TbVfN+UgnMbjE679LVjj1tb+wbT9NWwIFH7nQfzmYy4BNYvNn9gChFuCA4gAcJzbF4CH9xoSoYXPW+GcNZ+qaorzCgfMO2s+ftNGziYjCB/P9gqYM4/zRcUTAdq7m64aqmpQSSfZr7ItcHn9LvNDzqsd30a4kaYC8sSJ5imEmjcPzDoHLh1Q32JrqHE8W0779pSam1bcHBM8+s2Z8yVpqTXcNsejgEC0++HU24xaR4yzwyxTHCS1v5nwuVvQ/+Zrh0zdoh59PaDq5eZUu2YX5qMuNboK5rfvudI85i3x2RYc5oMn1XKpPnoFrOul8U0syRONB3wvU+pX3fAbBPMx1xpMq7oAfUBAkyAaEqpxkH8d4fNMZrjrGZ13VfmO1Nr0i3mcfWTZl/Tf+9axjjjD6aT/3jHr9UjHq7+zNSMxl9bPzKodiRebaCv1fsUM2hhwGwTqBuOCvMLafl4tWqb/Lz9TT/K8dI65zFTQFj/gvk9Nq3xtiMJECcre7VpkglLrM+0G9r2nqm2Z25yjJ9+0yzfs9yM3lg823y5Y4eaUn55rim5rF8Mb/3S/MAvfwfeuLi+6rv/W1OtTV9rvpxghngWpJmSF5jAEBwHU359bJoGnWsucOszuX74YWiTkVhR/Y/drj34hZi+hODYltdtqs/k+uaDWr1Gm5pJ1ACTiYNpRrr+K+f78PIyI6raotcouPDZ1m3TMNOYep/zjDRqgClZNwzIIy4xTXMxQxpsf6/JwFNmmu9FtKPvJPEU08cTP6bl9LSUOUf2hwFnm5pqbfCJ6AvevseuO+dxM8zU1VKzb6D5c1VYoulnaChhgqkV92vSDBwQDld/6vq+mxOaYEZvRQ9s+b3y9jN9ZxNvNDU4N5IAcbKqrjDtxQVpptTesBM2b58Z/TDqFyYwWPxMKTc8yYz8eekcMyoie3v9NnHDTUayfrFp/jn9bpMhhPSC8jzT7vvOQlPaDGiQ+Wx91zz2nWoenWWmtWKHwJWO0UI9R5nmgtqO2o4weK5p8mgPwy82f115gsRznzAdl6HNnPPUe2DEpY0zpLEL6wcB1PINhAFn1T9POs0Ex1l/NVeTN22uawul4PIl9U2bXt7gH+Z83YGzT/x4rdVzBPw+07VaSFvUFiBiBre8bq3oge5JSwMSIE4WVeVmhEj0IDPkz1ZZ/5q1qHEtonZ+oC1vm9FEv3jHNAEVpJkAcXSrKRWmfmbaaifebNrUQ2JN52VlsWlLVcp0Clfkm203v1l/oVrMUBNgtn9gjh3dyoy+zyS4N6111fATde4TLa/jqq4cGGo1vK7BmeiBbctk+kyCu/eY/y97/fjrtlZt30BQjNva1dvMXcGh1iUvu3f/bSAB4mRR6pivyFpsAoS9EnBkUtUVjQPErqXmsabajHqp7YANTzIjYyJTzMgiZ00PFz1vfgi1I5kmOobzVVvNdQb/GmmanCb9Cj66xQSJ3pPalmF2ZHAQJ4fafp7g6M5NhwAkQJwcdE39XD61V/varKZTWGsTIGrXK8021wIkT4UD35r24drpDsCMLKrlLFPvNcp5Gnz8zd+oBWbK7IFn178W6aZ+A+F5ghvUIIRLSqzVlFba6NkjoOWVW6mL1eG6n2nTpvHFF40nAXvyySe55ZZbjl1Za6ZNncr69evrl9lt5gKahoGhosAEBYu/6diyWU0zU8lR8//MR0wgsPjVDy1sL2f/A25YaWos3o4vZNSA9j2G8FxB0YBq22izTrQ1vQh7Tesn6nt3QzobDxUA8MPeXPbnND+p45MrdvO79+tHj2UWVbDpcCH3vreFeYtWU1bZ/h3WUoNwswULFrBkyRJmzaofwbJkyRL+8Y9/mCdam/4EH38zkqi6rHH/QmmWWRbW2wQGa7EJBmBGMygF1gaTknn7w7jbzPIbv208zLQ9eHlRV64I7QX5++qH6AlxoizeZp6ilDaO+HKz3NJKooL9Gi3bmVnM3EXf87cLh3PZBNd/b6lHS7j73c0khAcwtnc4H246QmJEAHeeOYDEiEDGJ9UPBimttPHst/upqLZTYq2mosrO5vQicktNXnH/OYMI8mv/7FwChJvNnz+fP/zhD1RWVuLn50fa/n0cOZLBG2+8wZ133klFaTHzz5nGw39/qv6+CJUlprmoPM9MNBcQYa4Gri5vPM2zt1/j0UuBURBgqW86as2IiLboEW8CRKQECNGOGs6i24Gs1Xb25ZTSq0cA7/2czvyxCaQXVKA13Pf+Fk5LieaZb/fx5KWjOH90PBsOFnDnW5sYHm+u/fl8+1FsNZqzhsSSV1ZF/5hgDuaVExPqR6h//Uyr2cVWwgJ9eXLFbry9FIfzKzicX8H8sQm8uyGdu97eTEyIH8vvnMq6tHyq7DXsySqlotpOkK+FpVsyCfX3JsDXwu0z+mPXmutP6+uW98SzAsRn95kRPO0pbjic/bdmX46MjGTChAl8/vnnzJs3jyWvvMClc6bzuz89RESPYOxZOznj0pvYsmYlI/rGAcpM2VBRaMaEW/zqR3ZYHCUX3yAzRYVPYP2MogHhZvx2Zgfe1Ss03nSCh/fpuGMK0QqVNjulVhuRwX5kFVvZn1PGpH6RVNlqsNdoNqcXcii/nA1pBRzILWNtWj6nD4hm1e4c/v55KlX2GmJD/cgqrmS741YBD3+ynV1HS3j/53SySyo5lF8OwDepOXyTmsN/Vu7lSJGV01KiWL03F38fC388dwhT+kfx/s8Z/PvrPYxMDGPDwQJuPyOFymo7vSMD+cXEPgyINUHl9Z8OMfH/VmCtrr/x04DYYP4xfyQ5JZVMHRiNza4J8HXvyCrPChCdpLaZad68eSx59wMWP/YAb7/5Os+9sBhbdSWZWbns2LqFEf16mSs3a/sZlMXUAmprBLUXZPmF1k9H7O1n+gB82r+DqkXjrzMXh7lhHnrRvRVbqwnx80a1YvSbtdrOofxyvt6VXdecEuhj4YLR8Xh5KWpqNO9vzKCoopq92SWk5ZbjbVGsTyvg4XlDeebbfRzILeOsIbFsOlzIaSnRvLvB3G3O19uLansNvhYvVu3OYWBsCNEhfhRVVLM1o4hzhsdxILecm6f147EvU3lu1T4GxoUyqGcoq3bn0DcqiP25ZSRFBpKWV06PAB++25NLdIgfA2NDuK9B30HfqCA2HCwg1N+ba09NpkdA/e/nhtP7obXmcEEFeaWV3DN7EOGBPhSUVzM4LoSY0PppN3zcPOoW3BwglFKzgX8BFuB5rfUxRW2l1DTgScAHyNVaT3V121Y7Tknfnc4/by533XUXP69fS0VFBeE9Qvnnk79j3dJXCY/vy1U33ILVajX9B16Oj6Sy2Fwo1PAH5BNkAkNAkwuIaoNFR0sYd/w5jIRo4EBuGQnhAXyx/Sh3LNnEr6b3586Z9QMcckoqCQ/0wdvixUebMnhu1X5C/X24e/ZABseFMuff37E/p+yY/X6wMYPoED++2H6U8qpj71seHeLHPe9uweKlCPHz5ovt5m5w725I54xBMVw9JZlxSeHklFTy76/38Pb6dO6cmcLsYT3JLKrgzZ8OcePUfnVB6byRvaip0Xh5KbYfKeL7PTncM3sQu7NKuHhcAgVl1cSG+nH3u1u4clIfJvWL5H+r9uPvY+GMwbHEhwVwy+s/c9bQ2EbBoZZSipevHt+q4OkubgsQSikL8DQwE0gH1imlPtZa72iwThjwH2C21vqQUirG1W1PJsE1RUybOIprrrmWBefPori0giB/P3qEBpFVYuezr39g2iljTS1AeZlAAMdeJ2DxlhFDosupqdFsSi9kdKIpuGw/UkxRRTVPrtjNA+cOYURCGJsPF3L+f1bTPzqYvTmlBPhYeHrlXpKjgticXsjKXdmk5ZUzMDaEKf2jWLz6AIN7hrI/t5QbX93AzCGx7M8p4w9zBjN1QDRFFdV4eSl2ZZbwx4+2UaM1l4xLZEr/KHwsXhRbq7FW29mZWcyDc4fy86EC/H0s5JVW8emWI+SVVfHdnlzunDmAYY4+hMSIQG6bkUJYoC8zBpkpWXr2COCus469mNDLy2TeQ3v1YM39ZxAd7MfsYXF12wAsvqp+Tq5bZzTup3t+4fELVl0hOIB7axATgL1a6/0ASqklwDygYSZ/OfC+1voQgNY6uxXbnhxq7FBRwILzZ3Hhdb9lyaI/MWjsqYweNoihZy6gb78Upkx0fFlqb30YFGWGkDqbdVWILuZ/3+3n/z7bxUNzh2CxePHAh/WzDd/+5kbG9Alnf04ZgT4WDuaXM29kL+6ePYhLnvmRO97ahK/Fi1NTorhwTAJvrTvM4tUHOGNQDM/8ciypR0uY9/Rq3vjpEAsmJHJdk87YMb3DGdorlGp7DeOSmp+0bnK/qLr/Zw6JJb2gnHVp+XXBoVZiRCD3n9O6wR0xIf4tr3SSUrq9brLddMdKzcfUDK5zPP8lMFFrfWuDdWqbloYCIcC/tNavuLJtg33cANwA0Lt377EHDza+WfvOnTsZPNjNo3mOpzy/8Q3kfUMck6Pp+hFIxZnmSunI/id8dXGnn6/wCFprSiptVNtqmPaPbyirsuHr7UWNhjG9w5g1NI6IIF/ufGsTvt5eWKtruHV6f26d0R9/R+N5la2G9Wn59I8Jrmtb11pTUF5NeKBPXSl65a5svLwUp6dEdVyJJsMAACAASURBVJmSdXeilNqgtXZapXFnDcLZJ9k0GnkDY4EzgADgR6XUGhe3NQu1fg54DmDcuHHuiXZtUZZr+hHAjPQBM/WFn2N++Ian6BdibmLi04oZJ4Vwo8LyKrZlFHNqStQxrxWVV/ObdzaxYmc2156aTEmljRcWjuP9jRn4eXtx39mD6krVU/pHEeLvzXe7czk1JaouOIDpGJ7cv/H+lVJEBDWewXX6oJPrornuxJ0BIh1IbPA8ATjiZJ1crXUZUKaUWgWMdHHbrktrEyBsFYAyUy/bbebm6M5qCH7B7r9mQYhW+PfXe3nh+wOsvm8G8WH1I+Q2Hy7kiud/osRx1e4rP6YRG+rHjEExnDH42KnUay8qO3NIG6ZZF53OnQFiHZCilErG3HvrMkyfQ0MfAYuUUt6ALzAReALY5cK2LtNad1zVtPiICQ61U2OgTVDQNeaaBTfWEtzVXChOnNaa7/fmcmr/k6OZZOUu0x347vp0skqs/LQ/jytO6cOGgwVYLIplt5/GHW9tZHdWKZP6Rp4U5yRaz21zMWmtbcCtwBfATuBtrfV2pdRNSqmbHOvsBD4HtgBrMcNZtzW3bVvS4e/vT15eXsdlnqXZ9cGh7sK2EHMldMwgt00TrbUmLy8Pf//u22F2Mvt2dw6/fGFt3RBLZ0qs1Uz529d8vav5dWz2GrKLrdQ0mffn1TUH+fdXe8grreTBj7bx+PLdzezB0Fof85tIPVrCf77Zyw/7ctmfa4aTPrFiN2+tO0ygrzcPf7KDpVsyOW9kL4b0CuX0FDPj6il9I497LHHycut1EFrrZcCyJsueafL8H8A/XNm2LRISEkhPTycnJ+dEd+WaohxTW/D2N9cr2GxQtKdDDu3v709CQkLLKwq3KCirYsPBAqfNKRsPFQKwfEcWs4bGHlPi3plZTF5pFRmFFSzfkcXpKdHc8dYmfjHRjKP/fFsmA+NCuenVDaRmlTCuTzgPnTeUIT1D2ZFZzB8/2obW8OGmDPbnlhHq78Po3mbY6fSBpg3fZq/h5R8P8tGmDPZklTIwLoQ3rp9IXmkVu7NKePTzXezOqr8S/8LR8XywKYN/LxjN2cPiuOX1n/ls21HmjzXfsXmj4lm+M0v6CLoxt41i6gzjxo3TjWZC7WiFh8xN3899ouWbtYhuJb+sigl/WYGtRvPZr09jcM/QRq9f/eJaVqaaQkpkkC+LLh/DpH6m5L39SBFznvqe/jHB7M0uZUBsML+fM4SFi9cyISmCWcPieGTpDgJ8LFRU27lqchJvrD1Ela2GOSN6klVkZX9uGbfN6M/Dn9SPBLd4KSxeilum9cPX24vVe3NZvTePUYlhDOkVyptrDzExOYKdmSUUVVQD8Mj5wyivtFFtr+Hmaf1JLyinT6S5LqfSZmdPVukxQ0PFya2zRjF5nuyd5rHh/XzFSW3joQK+3JHFnOE9j5sx/vnTHdgczT6bDxcSGezL62sOMXdkT/pFB7MlvYiIIF/yy6rIK6vi4U+28+hFIxjSK5R31pvpHvZmm9L7nuxSXl9jhkavTctnbVo+w+N7sDWjiAnJETw4dwjXnprMi6vTWLz6AABPXDqSeSPjWbolkx4BPny7Owd7jcbHonhyhanBKgWPXjScS8YlopQiMTyQ/323n+SoIC4aE09ppZ0rJvZuVLupDQ4Aft4WCQ4eRmoQ7em7x+Grh+Heg8dOhyG6pJoazZc7svjvN3sJDfDhsYtHkltaxZBepgZw2XM/smZ/Pj4WxT2zBlFps/Or6eYGSbUZ6de7srjmpfXcOLUvb/50iJlD4tiXU8qmw4V4Kfjd2YP5y7KdPDh3CD0CfLDZNfe8twWAqGBfKqrslDmmiOgR4FNXmj9zcCzr0vKZkBzBostH821qDsPie9DLMarIZq/hptc2MCgulN/OGlh3PkrB1S+to0bDbTP6U1ReTYCvhWp7DdMGSnOQaOx4NQgJEO3p5bmQnwZ3tvOMscJlWmse+3I3E/tGcFpKy7etvPudzbyzIZ2oYF9yS6sI8rVQVmVnxqAYHjl/GKc++jVXntKHL3dkkVlkBWDOiJ5szyjivrMH8/jyVHZnlZISE8z7t0zm5td+5vu9uYAprb+59jCbDhfiY1F89uvT6R8TjNaatQfyyS6p5IvtR9mSXsR5I3uxaOVerpmSzKdbj9ArLIAnLx1FVLAfgb6WVo8SqrabWUB9LHJPMHF80sTUEfasgAOrYNZfOzsl3VpBWRVhDa6yrbU7q4TYEH+WrDvEopV7WbYtiOevHEdYoC8RQb78sC+XiCBfBsaG8OSKPYT4e3PeqF58sDGDBRMS+dO8YVz23Bp2Z5Vw/WnJ/O+7A6S98BNawy8nJbFgYm9W783jv9/s49MtmQDc9NoGEsIDuGf2QK6Zkoy/j4WkqEC+3wtnDo7h0vG9OWNwLC//kMa8Ub3oH2Pu862UYqJj5M/ckb0A075/pKiCBRMS+ePcE2+ilMAg2oMEiPawaxm8ew1E9DVTYAu3yC6xctqjK/nlKX34w7kmE33jp0MM7hnCpc+tISzAhxzHHbYKyqq45Nkf6RMZxOyhcfxl2U6ign25aEwCz67aj1Lw86ECbDWa607ri4/Fi1eumUBFtZ2oYD9KrDZH8Ohdl7EPigslyNfC4tUHGBAbwqdbM3lqwWjG9A6vS+MFo+NZtTuXBxzpiwr24zdOJntrys/bwuOXNHM/cCE6iTQxtYfXLoKc3XDtlxDas+OP3w1Yq+2OCdl6N3sTlDd+OsT9H5jmu79dOJyRiWGc/a/vCPS1UF5l7rY1ITmCU1OieWRp43kdpw2M5od9eWbkz/CerEszTTxnDo7h+YXjnR2u2QsstdbYa8yc/clRnTTVuhDtRJqY3K00C2KHeHxwWLrlCK+vOcRr103E4tVym7nWmpzSSmJC/PloUwZ/cmTq15yaDEBRRTV/XrqD8ckRzB+TwJc7jpIYEUByVDD3vb+VQXFm2pLyKjspMcF8fOup+Pt41d35y8eiGNqrB4kRgTxxyUjWHyzAZtdM6R9JWl452cVWxvQJd544mp9yWSmFt0VJcBDdngSI9lCaDb1Gd3YqOt1Lq9NYf7CAb1KzySyyMndkL6c3RAEoq7Rxz3tb+HRLJgsmJNZdoPXWusNcPSUJgN+9v4VlW4/yzoZ0Nh4q5Ie9eVw5qQ93zx7I7W9u5IvtWZwxKIaD+eVcOTmpruYxKC6EAB8L45LCeeWaCXUZfcMrfpOjgiSDF6IFEiBOVI0dynIg2LMnI8sutrLhUAEAt76xkYpqO08s382LV4/nSKGV0ABvXvjuANEhfvSNDmLV7lx+3J/HWUNiWbLuMFpDv+ggUrNKOOuJVSyY0JtlW49y96yBpB4t4c21hwjx8+aXk/rg523h6cvH8Nqag5w5JJaE8MbzW3lbvHj6F6NJDA+UOYKEOAESIE5UeZ6ZWsPDA8SnWzPRun4c/5mDY/jpQD7nLVpdt05UsC9aQ15ZFWCGgV46vjc/7M3llR8P8vs5g3lr3WFeXXOQPy3dQUSQL9eemkxppY2ckkpuOL1v3YVb3hYvrpqS3Gx6au8IJoRoOwkQJ6rUMbGaBweIEms1T6/cx+jeYYyI78HLPx7k7lmDyCgs5/nvDnDWkFi2ZBTx+3MGExnsR1F5NVabnVjHTWIm94+quy/Ab2cNJMTfm//7bBeXjU/E38eCv4+FN284pTNPUQiPJAHiRJV4boCoqdH8+dOdvPxjGjVas/iqccSG+jMhOZKBcSEMjAtxWpLvEehDD5z3TQAsnJxEla2GK07p48bUCyFaIgHiRNXVILrXFAZ/XbaTvdml/PWC4cT1OHYK8bfXH+Zvn+0iv6yKC0bHM29UL0YkmOlF5ow4sdFc/j4WbjsjpeUVhRBuJQHiRHWjALH4+wOEB/kwc0gcL/+QRqWthnOe+o4zB8cQF+rPrTNSyC+rothazV8+3UlCeAD3nzOYi8bES2ewEN2QBIgTVZptbgjke3IOmcworCDYz5tDeeU88ukOEsLNRHCVthr+ftEIXv4xjaVbMimvsvP89wcor7LXbfvKNRMYmSiTEgrRXUmAOFGlRyG45UnhuoLv9+TSPya4rsloW0YRlzz7I0N6hqIxt9I+nF/Bf7/ZR68e/swfm8Al4xOpqdEs35nF6r25JIQHUGq1gVISHITo5iRAnKjMzRA9qLNT0aK/f76L/3yzj5GJYXxw82QqbTXc+OoGbDWa9QfN9Qu/mt6Pp1fuY3dWKXfPGoiX42poLy/FrKFxzBoa15mnIIToYDLl44koyYL8/dB7UmenpJHc0spG9ywuLK/iv9/uY2BsCJsPF/L7D7fx0MfbySis4IWF44gPC2BUYhi/mTmQPpGBxIT4cc1xrjEQQngGqUGciEM/msc+kzs3HQ1kl1iZ+vdvOHNILP+8eAS+Fi/W7M9Ha3M7ybfXH+ad9Yex1WjOH9WL01KiWXrbqQT4WvDyUvx7wWi8lGp2wjwhhOeQAHEiDv0IPoHQc2Rnp6TOsi2ZVFTb+WTzET7ZfITkqCDsNZoAHwujEsOYkBzBH+cOobCsmsQI0yEdHuRbt33tUFUhhJAmphOx/xtInACW5i/6cqfD+eVM+MsKvt+TS2mlDXuN5qPNRxgUF8KjFw3njjNT8LV4cSi/nOSoIHy9zccd6u9D70iZp0gIcXxSg2irgjTI2QVjFnZaEv799R6ySyp5dtU+1qWZZqRKWw2/P2cwl47vDcCVk5K48dX1/GKiXJUshGgdCRBttftL8zhgVocfuspWw8G8Mt77OQNvL8V3e8w9kC8bn8j4pAjOHx1ft25EkC/v3NR1+kiEECcPCRBtte9rc4vRyH4detj9OaXMenIVPhYvQvy9uXV6f/786U5O7R/F3y4a0aFpEUJ0b9IH0VZ5eyBuuNsPU1Zp4/NtmVTbawBYmZpDtV1TXmXn4fOGctGYBBLCA7j2NBmWKoRoX1KDaIsaOxQegkFz3HqY9IJyLv/fTxzKL+f2Gf05e3hPVu/NJTkqiC/vPB0fi4nv3987w63pEEJ4JgkQbVGSCfYqCE9yy+5zSip56YcDbEkvIre0klP7R/HU13t56uu9ACyY0LsuOAghhLtIgGiLgoPm0Q0BQmvN3e9u5pvUHADumT2QBeN789TXezhaZOWzbUeZNvDkmPtJCHFykwDRFgVp5jHsxIeOllXa2JlZzNg+4Sil+HjzEb5JzeH2M1Lo2cOfi8Yk4OvtxYNzh6K1Zm92Kf1jgk/4uEII0RIJEG1RkAbKC3oktnkXFVV2XvohjbfWHSItr5yZQ2IZHBfCez9nMCw+lDvOSKmbLK+WUoqU2JATTLwQQrjGrQ3ZSqnZSqlUpdRepdR9Tl6fppQqUkptcvz9scFraUqprY7l692ZzlYrSIPQBPD2bXHV5vzrqz08+vkufCxeXDU5iTX78li0ci8ZhRXcf87gY4KDEEJ0NLfVIJRSFuBpYCaQDqxTSn2std7RZNXvtNbnNrOb6VrrXHelsc2KDkNY7zZvrrVm2dZMTh8QzSvXTADgofOGUlZpI7PIKk1IQoguwZ01iAnAXq31fq11FbAEmOfG43Wc0iwIiW3TpkeLrDyxfDeH8ss5Z1jj+ysE+XlLcBBCdBnuDBDxwOEGz9Mdy5qapJTarJT6TCk1tMFyDXyplNqglLqhuYMopW5QSq1XSq3Pyclpn5S3pCQLgtsWIB74aBtPfb0Xfx8vZg5p2z6EEKIjuLOT2lkjum7y/Gegj9a6VCl1DvAhkOJ4bYrW+ohSKgZYrpTapbVedcwOtX4OeA5g3LhxTfff/ipLobqsTQFiS3ohy3dkcfO0flw1OYnIYD83JFAIIdqHO2sQ6UDDYT4JwJGGK2iti7XWpY7/lwE+Sqkox/Mjjsds4ANMk1XnK80yj60IEKWVNrZlFPHnT3cSHujDLdP6ERvq76YECiFE+3BnDWIdkKKUSgYygMuAyxuuoJSKA7K01lopNQETsPKUUkGAl9a6xPH/WcCf3JhW15Vmm8fgGJc3eezLVF5cnQbA/104nBD/zrl/hBBCtIbbAoTW2qaUuhX4ArAAi7XW25VSNzlefwaYD9yslLIBFcBljmARC3zguKGNN/CG1vpzd6W1VVpZg7DZa1ix02xz1eQkLhnX9msnhBCiI7n1QjlHs9GyJsueafD/ImCRk+32A13nPp4N1dUgjh8grNV2bn9zIxsPF5JTUslDc4dw1RSZcVUIcfKQK6lbqzQLlAUCI4672mNfpvLljix8LKav/vQBMn+SEOLkIgGitUqzICgavCzNrqK1ZumWTM4cHMvsYXF8k5pNclRQByZSCCFOnASI1irNbrGDeltGMZlFVu6aOYD5YxOYPzahgxInhBDtRwJEa5XlmBqEE3uySvjrsp2sP1iAl4IzBsuFcEKIk5cEiNayFkGE887m+z/YSurREmYOjmVwz1Aigto+mZ8QQnQ2CRCtZS0C/x7HLM4orGBdWgF3zRzA7WekONlQCCFOLnLfytbQGqyFTgPE0s3mIvHzRvbq6FQJIYRbSIBojepyqLGBf9gxL328+QgjEnqQJKOVhBDdhASI1qgoNI9NahD7ckrZfqRYag9CiG5FAkRrWIvMY0DjGsQnm4+gFMyVACGE6EZcChBKqfeUUnOUUp4dUGoDRJMaxLq0fIb16iEztAohuhVXM/z/YmZi3aOU+ptSapAb09R1WZ03MaXlltMvWvoehBDdi0sBQmu9Qmv9C2AMkIa5gc8PSqmrlVKeM3d1XQ2ivonJWm3nSFEFfSIlQAghuheXm4yUUpHAVcB1wEbgX5iAsdwtKeuK6jqp6wPE4fxytEbmWhJCdDsuXSinlHofGAS8CszVWmc6XnpLKbXeXYnrcpz0QaTllQPI8FYhRLfj6pXUi7TWXzt7QWs9rh3T07VZC8E3GCz1b1tabhkASZGBnZUqIYRwC1ebmAYrperaVZRS4UqpW9yUpq7LyTQbB/LKCAv0ISxQ5l0SQnQvrgaI67XWhbVPtNYFwPXuSVIXZi065irqXZnF9I8O7qQECSGE+7gaILyU4wbRAEopC+B5ReaKxvMwWavtbM0oYmxSeCcmSggh3MPVPogvgLeVUs8AGrgJ+Nxtqeqqqkob3Qti0+FCqu2aCUnHv/2oEEKcjFwNEPcCNwI3Awr4EnjeXYnqsmyV4FN/tfS6A/kAjO0jNQghRPfjUoDQWtdgrqb+r3uT08XZK8G7PkBsOFTAgNhg6aAWQnRLrl4HkQL8HzAEqMshtdZ93ZSurslWCd5+dU93ZhYzpX9UJyZICCHcx9VO6hcxtQcbMB14BXPRnGexWetqEPllVWQVVzI4LrSTEyWEEO7haoAI0Fp/BSit9UGt9UPADPclq4uyVYLF1CB2ZRYDMKhnSGemSAgh3MbVTmqrY6rvPUqpW4EMIMZ9yeqibNa6JqadR0sAGCQ1CCFEN+VqDeIOIBC4HRgLXAEsdFeiuiS7zdxu1NHEtCuzmKhgP6JD/FrYUAghTk4t1iAcF8VdorW+GygFrnZ7qroie6V5dNQg9uWUkhIjV1ALIbqvFmsQWms7MLbhldQeyVYbIEwNIr2ggoTwgE5MkBBCuJerfRAbgY+UUu8AZbULtdbvuyVVXZHNah69/ai02ckuqSQhXGZwFUJ0X64GiAggj8YjlzTgQQGivgZxpNAEC6lBCCG6M1evpG5Tv4NSajbmznMW4Hmt9d+avD4N+Ag44Fj0vtb6T65s2+Fs9X0Q6QXmJkHxEiCEEN2Yq1dSv4ipMTSitb7mONtYgKeBmUA6sE4p9bHWekeTVb/TWp/bxm07Tl0Tkz/pBRWA1CCEEN2bq01MSxv87w9cABxpYZsJwF6t9X4ApdQSYB7gSiZ/Itu6R4MaREZBBRYvRVyo//G3EUKIk5irTUzvNXyulHoTWNHCZvHA4QbP04GJTtabpJTajAk4v9Vab2/FtiilbgBuAOjdu3cLSToBDTqp0wvK6dnDH2+Lq5eRCCHEyaetOVwK0FJu7GxYbNNmqp+BPlrrkcC/gQ9bsa1ZqPVzWutxWutx0dHRzlZpHw06qdMLKogPk+YlIUT35lKAUEqVKKWKa/+ATzD3iDiedCCxwfMEmjRLaa2Ltdaljv+XAT5KqShXtu1wjWoQFTLEVQjR7bnaxNSWGenWASlKqWTM3E2XAZc3XEEpFQdkaa21UmoCJmDlAYUtbdvhHDWIKuVLVolVOqiFEN2eq6OYLgC+1loXOZ6HAdO01h82t43W2uaY2O8LzFDVxVrr7UqpmxyvPwPMB25WStmACuAyrbUGnG7b5rNsD44aRHY5aC1DXIUQ3Z+ro5ge1Fp/UPtEa12olHqQ+j4DpxzNRsuaLHumwf+LgEWubtupHAHiSKnpCpEahBCiu3O1k9rZeq4Gl+7BXgVAeokdgETpgxBCdHOuBoj1SqnHlVL9lFJ9lVJPABvcmbAux1GDOFxcg5eCuB5yDYQQontzNUDcBlQBbwFvY/oLfuWuRHVJjk7qg4U24kL98ZFrIIQQ3Zyro5jKgPvcnJauzXE/6owiq3RQCyE8gqvXQSx3jFyqfR6ulPrCfcnqghz3o84vqyIySO4iJ4To/lxtJ4nSWhfWPtFaF+Bp96R23I+6oLyasECfzk6NEEK4nasBokYpVTe1hlIqiWamvui2bJVobz+KKqoIC/Tt7NQIIYTbuTpU9ffA90qpbx3PT8cxQZ7HsFnRFj+q7ZpwqUEIITyAq53UnyulxmGCwibMTX4q3JmwLsdWic3L9D1IE5MQwhO4OtXGdcCvMZPmbQJOAX6k8S1IuzebFZuXaVqSJiYhhCdwtQ/i18B44KDWejowGshxW6q6IlsVVZiaQ1iA1CCEEN2fqwHCqrW2Aiil/LTWu4CB7ktWF2SzUoWpOYQHSQ1CCNH9udpJne64DuJDYLlSqoDOvj9DR7NVUomZ9Vz6IIQQnsDVTuoLHP8+pJRaCfQAPndbqroim5UKZd6usACpQQghur9Wz8iqtf625bW6IVslFRZvgnwt+HrLPExCiO7Ps6bsPhE2K+XKW0YwCSE8hgQIV9kqKfWySP+DEMJjSFuJq2xWSuzeEiCEEB5DAoQrtAZ7JeV2b4L9pNIlhPAMEiBc4bjdaKndmyBfCRBCCM8gAcIVjtuNltktBPpZOjkxQgjRMSRAuMJxu9ESm0VqEEIIjyEBwhW1NYgabwIlQAghPIQECFc4ahCV2pcgaWISQngICRCucNQgKpEahBDCc0iAcEVtDQIfqUEIITyGBAhX1NUgfKUGIYTwGBIgXFEbILQPQb5SgxBCeAYJEK5o0MQUKFdSCyE8hAQIVzTsg5AahBDCQ0iAcEWjTmqpQQghPINbA4RSarZSKlUptVcpdd9x1huvlLIrpeY3WJamlNqqlNqklFrvznS2qK4PwleupBZCeAy35XZKKQvwNDATSAfWKaU+1lrvcLLeo8AXTnYzXWud6640uqxBDSJAmpiEEB7CnTWICcBerfV+rXUVsASY52S924D3gGw3puXEOGoQWHzldqNCCI/hztwuHjjc4Hm6Y1kdpVQ8cAHwjJPtNfClUmqDUuqG5g6ilLpBKbVeKbU+JyenHZLthKMG4e3r7579CyFEF+TOAKGcLNNNnj8J3Ku1tjtZd4rWegxwNvArpdTpzg6itX5Oaz1Oaz0uOjr6xFLcHJsVOxb8/fzcs38hhOiC3Nnjmg4kNnieABxpss44YIlSCiAKOEcpZdNaf6i1PgKgtc5WSn2AabJa5cb0Ns9WSbXyJVD6H4QQHsSdNYh1QIpSKlkp5QtcBnzccAWtdbLWOklrnQS8C9yitf5QKRWklAoBUEoFAWcB29yY1uOzWalSvnKRnBDCo7gtx9Na25RSt2JGJ1mAxVrr7UqpmxyvO+t3qBULfOCoWXgDb2itP3dXWltkq6RKLpITQngYtxaJtdbLgGVNljkNDFrrqxr8vx8Y6c60tYq90kyzIddACCE8iIzZdIXNilX70CPAp7NTIoQQHUYChCtslVTUSIAQQngWCRAu0NVWyrU3oQHSxCSE8BwSIFxgr6qgSntLDUII4VEkQLjAXm2lEl9C/SVACCE8hwQIF+jqCqxIH4QQwrNIgHBFVTkV+BMqAUII4UEkQLhA2Sqo0L5SgxBCeBQJEC6w2K1U4CejmIQQHkUCREtqavC2V1CBn9QghBAeRQJESxw3C6pSfgT4yFxMQgjPIQGiJdUVANR4B+KYPFAIITyCBIiWVJcBoHwDOzkhQgjRsSRAtMRRg/CSACGE8DASIFpSZWoQXn5BnZwQIYToWBIgWuKoQXj7SQ1CCOFZJEC0pLaJSWoQQggPIwGiJY5OaosECCGEh5EA0QJdVQ6AjwQIIYSHkQDRgmqrI0AEBHdySoQQomNJgGhBlbUEAN8AqUEIITyLBIgW2KymD8JPahBCCA8jAaIFNmsZVdpCYEBAZydFCCE6lASIFtgry7DiR5CfTNQnhPAsEiBaYK8qpxw/gvzkXhBCCM8iAaIFurKMCu1LkK8ECCGEZ5EA0ZLqCmliEkJ4JAkQLal2NDFJDUII4WEkQLTAy1ZumpikD0II4WEkQLTAy2bFqvzx9Za3SgjhWSTXa4GvrZgKL7mKWgjhedwaIJRSs5VSqUqpvUqp+46z3nillF0pNb+127pVTQ0hVbkUWqI65fBCCNGZ3BYglFIW4GngbGAIsEApNaSZ9R4Fvmjttm5XkY83Nop9JEAIITyPO2sQE4C9Wuv9WusqYAkwz8l6twHvAdlt2Na9SjIBKPWVACGE8DzuDBDxwOEGz9Mdy+oopeKBC4BnWrttg33coJRar5Ran5OTc8KJbqTkKAAVfjHtu18hhDgJuDNAKCfLdJPnTwL3aq3tbdjWLNT6Oa31OK31uOjo6DYk8zgcNYjKAAkQQgjP487B/elAYoPnCcCRJuuMA5YoVnPFKgAAB5tJREFUpQCigHOUUjYXt3W7muJMvICQKKeVFyGE6NbcGSDWASlKqWQgA7gMuLzhClrr5Nr/lVIvAUu11h8qpbxb2rYjlOWmU6VD6BsX0dGHFkKITue2AKG1timlbsWMTrIAi7XW25VSNzleb9rv0OK27kprc6wFGeTqcFJi5WZBQgjP49b5I7TWy4BlTZY5DQxa66ta2rbDFR8hS4czOjqkU5MhhBCdQa6kbk5BGpElqez36UePQJ/OTo0QQnQ4mYEOYONrUGNrvGzPcmpQbIi+kGs6J1VCCNGpJEAALLsbqsuPWfy+bSrDBnf8BdxCCNEVSIAAuO1nXvrhAKlZxQDU1Gg2HiqkMiSKL6YkdW7ahBCik0iAAEp8o3j425+JCvYjLMD0N6T0j+FX0/vj7yN3khNCeCYJEMDWjCK0hn9ePJKpA9r5amwhhDhJySgmYPPhIgBGJvTo5JQIIUTXIQEC2Hy4kKTIQMICfTs7KUII0WVIgAA2pxcyMjGss5MhhBBdisf3QVTZapjSP4rTUuSeD0II0ZDHBwhfby/+efHIzk6GEEJ0OdLEJIQQwikJEEIIIZySACGEEMIpCRBCCCGckgAhhBDCKQkQQgghnJIAIYQQwikJEEIIIZxSWuvOTkO7UUrlAAfbuHkUkNuOyelMci5dT3c5D5Bz6araei59tNZOp7HuVgHiRCil1mutx3V2OtqDnEvX013OA+Rcuip3nIs0MQkhhHBKAoQQQginJEDUe66zE9CO5Fy6nu5yHiDn0lW1+7lIH4QQQginpAYhhBDCKQkQQgghnPL4AKGUmq2USlVK7VVK3dfZ6WktpVSaUmqrUmqTUmq9Y1mEUmq5UmqP4zG8s9PpjFJqsVIqWym1rcGyZtOulPqd43NKVUrN6pxUO9fMuTyklMpwfDablFLnNHitK59LolJqpVJqp1Jqu1Lq147lJ9Vnc5zzOOk+F6WUv1JqrVJqs+NcHnYsd+9norX22D/AAuwD+gK+wGZgSGenq5XnkAZENVn2d+A+x//3AY92djqbSfvpwBhgW0tpB4Y4Ph8/INnxuVk6+xxaOJeHgN86Wbern0tPYIzj/xBgtyPNJ9Vnc5zzOOk+F0ABwY7/fYCfgFPc/Zl4eg1iArBXa71fa10FLAHmdXKa2sM84GXH/y8D53diWpqltV4F5DdZ3Fza5wFLtNaVWusDwF7M59clNHMuzenq55Kptf7Z8X8JsBOI5yT7bI5zHs3pkucB/H979xciZR2Fcfz7VCbmRlJoiEb+yYsobCvoIiuCItKrAiOpRCLoxi68i7A/0L3dRUl0YbVEVC5JV9VCC16E4rZtVkbUTYvi3pSxQRHr6eJ3piZ5Z5g1x3de5vnAMDO/fXc4h7PvnnnfmTlDFPN5d0legj7XZNgbxBrg57b7s3T/AxpEAXwi6Zikp3Pt2og4BWUnAVbVFt3idYq9qbV6RtJMnoJqHf43JhdJ64BbKc9YG1ubc/KABtZF0qWSpoE54NOI6HtNhr1BqGKtae/73RIRtwFbgd2S7qk7oD5pYq1eAzYCo8ApYF+uNyIXSSPAh8CeiPit26YVawOTT0UejaxLRCxExCiwFrhD0s1dNr8guQx7g5gFrmu7vxY4WVMs5yUiTub1HDBOOYw8LWk1QF7P1RfhonWKvXG1iojTuVOfBd7g30P8gc9F0hLKP9WxiDiYy42rTVUeTa4LQET8CnwOPEifazLsDeIosEnSekmXAzuAQzXH1DNJyyVd2boNPAAcp+SwKzfbBXxUT4TnpVPsh4AdkpZKWg9sAo7UEF/PWjtuephSGxjwXCQJeBP4LiJeaftRo2rTKY8m1kXSSkkr8vYy4H7gBP2uSd2vztd9AbZR3t3wI7C37ngWGfsGyjsVvgK+acUPXANMAD/k9dV1x9oh/ncph/h/UZ7xPNUtdmBv1ul7YGvd8feQy9vA18BM7rCrG5LLXZTTETPAdF62Na02XfJoXF2AzcCXGfNx4MVc72tNPGrDzMwqDfspJjMz68ANwszMKrlBmJlZJTcIMzOr5AZhZmaV3CDMBoCkeyV9XHccZu3cIMzMrJIbhNkiSHoi5/JPS9qfA9TmJe2TNCVpQtLK3HZU0hc5FG68NRRO0g2SPsvZ/lOSNubDj0j6QNIJSWP5SWCz2rhBmPVI0o3Ao5QBiaPAAvA4sByYijI0cRJ4KX/lLeDZiNhM+eRua30MeDUibgHupHwCG8q00T2UWf4bgC19T8qsi8vqDsCsQe4DbgeO5pP7ZZThaGeB93Kbd4CDkq4CVkTEZK4fAN7P2VlrImIcICL+AMjHOxIRs3l/GlgHHO5/WmbV3CDMeifgQEQ8959F6YVztus2v6bbaaM/224v4P3TauZTTGa9mwC2S1oF/3wf8PWU/Wh7bvMYcDgizgC/SLo713cCk1G+j2BW0kP5GEslXXFRszDrkZ+hmPUoIr6V9DzlG/wuoUxu3Q38Dtwk6RhwhvI6BZTxy69nA/gJeDLXdwL7Jb2cj/HIRUzDrGee5mr2P0maj4iRuuMwu9B8isnMzCr5CMLMzCr5CMLMzCq5QZiZWSU3CDMzq+QGYWZmldwgzMys0t/hYGizjPrDUQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DA  DK  DQ  DJ  D10  D9  D8  D7  D6  HA  HK  HQ  HJ  H10  H9  H8  H7  H6  \\\n",
      "0   0   1   1   1    0   1   0   0   0   0   0   0   0    1   0   0   1   0   \n",
      "\n",
      "   SA  SK  SQ  SJ  S10  S9  S8  S7  S6  CA  CK  CQ  CJ  C10  C9  C8  C7  C6  \\\n",
      "0   1   0   0   0    0   0   0   0   0   0   0   0   0    0   1   0   0   1   \n",
      "\n",
      "   D_J9  D_AKQ  D_AK  D_AJ9  D_AJKQ  D_A9KQ  H_J9  H_AKQ  H_AK  H_AJ9  H_AJKQ  \\\n",
      "0     1      0     0      0       0       0     0      0     0      0       0   \n",
      "\n",
      "   H_A9KQ  S_J9  S_AKQ  S_AK  S_AJ9  S_AJKQ  S_A9KQ  C_J9  C_AKQ  C_AK  C_AJ9  \\\n",
      "0       0     0      0     0      0       0       0     0      0     0      0   \n",
      "\n",
      "   C_AJKQ  C_A9KQ  \n",
      "0       0       0  \n",
      "   DIAMONDS    HEARTS    SPADES     CLUBS   OBE_ABE   UNE_UFE      PUSH\n",
      "0   0.51996  0.000139  0.000058  0.000011  0.021558  0.001509  0.456765\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    DIAMONDS\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hand = np.array([[0,1,1,1,0,1,0,0,0, 0,0,0,0,1,0,0,1,0, 1,0,0,0,0,0,0,0,0, 0,0,0,0,0,1,0,0,1]])\n",
    "hand = pd.DataFrame(data=hand, columns=cards)\n",
    "\n",
    "for color in 'DHSC':\n",
    "    # Jack and nine combination\n",
    "    new_col = '{}_J9'.format(color)\n",
    "    hand[new_col] = hand['{}J'.format(color)] & hand['{}9'.format(color)]\n",
    "    \n",
    "    #Ace King and Queen\n",
    "    new_col = '{}_AKQ'.format(color)\n",
    "    hand[new_col] = hand['{}A'.format(color)] & hand['{}K'.format(color)] & hand['{}Q'.format(color)]\n",
    "\n",
    "    #Ace and King\n",
    "    new_col = '{}_AK'.format(color)\n",
    "    hand[new_col] = hand['{}A'.format(color)] & hand['{}K'.format(color)]\n",
    "\n",
    "    #Ace Jack and Nine\n",
    "    new_col = '{}_AJ9'.format(color)\n",
    "    hand[new_col] = hand['{}A'.format(color)] & hand['{}J'.format(color)] & hand['{}9'.format(color)]\n",
    "\n",
    "    #Acem Jack, King, Queen\n",
    "    new_col = '{}_AJKQ'.format(color)\n",
    "    hand[new_col] = hand['{}A'.format(color)] & hand['{}J'.format(color)] & hand['{}K'.format(color)] & hand['{}Q'.format(color)]\n",
    "\n",
    "    #Ace, 9, King, Queen\n",
    "    new_col = '{}_A9KQ'.format(color)\n",
    "    hand[new_col] = hand['{}A'.format(color)] & hand['{}9'.format(color)] & hand['{}K'.format(color)] & hand['{}Q'.format(color)]\n",
    "\n",
    "print(hand)\n",
    "input_hand = np.array([hand.iloc[0].values])\n",
    "prediction = model.predict(input_hand)\n",
    "result = pd.DataFrame(data=prediction, columns=[\"DIAMONDS\", \"HEARTS\", \"SPADES\", \"CLUBS\", \"OBE_ABE\", \"UNE_UFE\", \"PUSH\"])\n",
    "print(result)\n",
    "result.idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(\"E:/Work/trump_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
